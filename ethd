#!/usr/bin/env bash
set -Eeuo pipefail

__project_name="Eth Docker"
__app_name="Ethereum node"
__sample_service="consensus"
__docker_exe="docker"
__compose_exe="docker compose"
__compose_upgraded=0
__target_pg=17


__dodocker() {
  $__docker_sudo $__docker_exe "$@"
}


__docompose() {
# I want word splitting here
# shellcheck disable=SC2086
  $__docker_sudo $__compose_exe "$@"
}


__determine_distro() {
# Determine OS platform
  __uname=$(uname | tr "[:upper:]" "[:lower:]")
# If Linux, try to determine specific distribution
  if [ "$__uname" = "linux" ]; then
# If available, use LSB to identify distribution
    if [ -n "$(command -v lsb_release 2>/dev/null)" ]; then
      __distro=$(lsb_release -i | cut -d: -f2 | sed s/'^\t'//)
# Otherwise, use release info file
    else
      __distro=$(find /etc -maxdepth 1 -type f -name '[A-Za-z]*[_-][rv]e[lr]*' \
        | grep -v "lsb" | cut -d'/' -f3 | cut -d'-' -f1 | cut -d'_' -f1)
    fi
  else
    __distro=""
  fi
# For everything else (or if above failed), just use generic identifier
  [ "$__distro" = "" ] && __distro=$__uname
  unset __uname
  __distro=$(echo "$__distro" | tr "[:upper:]" "[:lower:]")

  if [[ "$__distro" = "ubuntu" ]]; then
    if [ "$__cannot_sudo" -eq 0 ]; then
      if ! dpkg-query -W -f='${Status}' lsb-release 2>/dev/null | grep -q "ok installed"; then
        echo "Installing lsb-release"
        ${__auto_sudo} apt-get update && ${__auto_sudo} apt-get -y install lsb-release
      fi
    fi
    if [ -n "$(command -v lsb_release 2>/dev/null)" ]; then
      __os_major_version=$(lsb_release -r | cut -d: -f2 | sed s/'^\t'// | cut -d. -f1)
    else
      __os_major_version=24 # Without sudo and lsb_release let's just skip the check
    fi
  elif [[ "$__distro" =~ "debian" ]]; then
    if [ "$__cannot_sudo" -eq 0 ]; then
      if ! dpkg-query -W -f='${Status}' lsb-release 2>/dev/null | grep -q "ok installed"; then
        echo "Installing lsb-release"
        ${__auto_sudo} apt-get update && ${__auto_sudo} apt-get -y install lsb-release
      fi
    fi
    if [[ -n "$(command -v lsb_release 2>/dev/null)" && $(lsb_release -r | cut -f2 2>/dev/null) =~ ^[0-9]+$ ]]; then
      __os_major_version=$(lsb_release -r | cut -f2)
    else
      __os_major_version=12 # Without sudo and lsb_release let's just skip the check
    fi
  fi
}


__handle_docker() {
  set +e
  if [[ ( "$__distro" =~ "debian" || "$__distro" = "ubuntu" ) ]] && ! grep -qi microsoft /proc/version; then
    systemctl status docker >/dev/null
    __result=$?
    if [ ! "${__result}" -eq 0 ]; then
      echo "The Docker daemon is not running. Please check Docker installation."
      echo "\"sudo systemctl status docker\" and \"sudo journalctl -fu docker\" will be helpful."
      echo "Aborting."
      exit 1
    fi
  fi
  set -e

  __docker_version=$(docker --version | awk '{ gsub(/,/, "", $3); print $3 }')
  __docker_major_version=$(docker --version | awk '{ split($3, version, "."); print version[1]; }')
  if [ "${__docker_major_version}" -lt 23 ]; then
    __old_docker=1
    echo "Docker ${__docker_version} detected"
  else
    __old_docker=0
  fi
  __docker_sudo=""
  if ! docker images >/dev/null 2>&1; then
    if [ "$__cannot_sudo" -eq 1 ]; then
      echo "Cannot call Docker and cannot use sudo. Please make your user part of the docker group"
      exit 1
    fi
    echo "Will use sudo to access Docker"
    __docker_sudo="sudo"
  fi
  if [[ -f "${__env_file}" && ( "$__distro" =~ "debian" || "$__distro" = "ubuntu" ) ]] && ! grep -qi microsoft /proc/version; then
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
    DOCKER_ROOT=$(__dodocker system info --format '{{.DockerRootDir}}')
    __var=DOCKER_ROOT
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"

    __var=NODE_EXPORTER_IGNORE_MOUNT_REGEX
    __get_value_from_env "${__var}" "${__env_file}" "__value"
    __regex="^'\^/\(dev\|proc\|sys\|run\|.+/\.\+\)\(\$\|/\)'$"
    if [[ "${__value}" =~ ${__regex} ]]; then
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
      NODE_EXPORTER_IGNORE_MOUNT_REGEX="'^/(dev|proc|sys|run|${DOCKER_ROOT#/}/.+)($|/)'"
      __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
    fi
  fi
}


__handle_root() {
  __cannot_sudo=0
  if [ "${EUID}" -eq 0 ]; then
    __as_owner="sudo -u ${OWNER}"
    __auto_sudo=""
  else
    __as_owner=""
    if groups | grep -q '\bsudo\b' || groups | grep -q '\badmin\b'; then
      __auto_sudo="sudo"
    else
      __auto_sudo=""
      __cannot_sudo=1
    fi
  fi
}


__upgrade_compose() {
  if ! type -P docker-compose >/dev/null 2>&1; then
    echo "Docker Compose has already been updated to V2"
    return
  fi
  echo "Updating Docker Compose to V2"
  if [[ "$__distro" = "ubuntu" ]]; then
    if [ "${__os_major_version}" -lt 22 ]; then
      echo "${__project_name} cannot update Docker Compose on Ubuntu ${__os_major_version}."
      echo "Consider upgrading to 22.04 and then 24.04."
      exit 1
    fi
    ${__auto_sudo} apt-get update
    ${__auto_sudo} apt-get install -y docker-compose-v2 docker-buildx
    echo "Installed docker-compose-v2"
    __old_compose=0
    __compose_upgraded=1
    if dpkg-query -W -f='${Status}' docker.io 2>/dev/null | grep -q "ok installed"; then
        ${__auto_sudo} apt-mark manual docker.io
    elif dpkg-query -W -f='${Status}' docker-ce 2>/dev/null | grep -q "ok installed"; then
        ${__auto_sudo} apt-mark manual docker-ce
    fi
    ${__auto_sudo} apt-get remove -y docker-compose
    echo "Removed docker-compose"
  elif [[ "$__distro" =~ "debian" ]]; then
    ${__auto_sudo} apt-get update && ${__auto_sudo} apt-get -y install ca-certificates curl gnupg
    if [ "${__os_major_version}" -lt 11 ]; then
        echo "${__project_name} cannot update Docker Compose on Debian ${__os_major_version}."
        echo "Consider upgrading to 11 and then 12."
        exit 1
    fi
    ${__auto_sudo} mkdir -p /etc/apt/keyrings
    ${__auto_sudo} curl -fsSL https://download.docker.com/linux/debian/gpg | ${__auto_sudo} gpg --dearmor --yes \
    -o /etc/apt/keyrings/docker.gpg
    ${__auto_sudo} echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
        https://download.docker.com/linux/debian $(lsb_release -cs) stable" \
        | ${__auto_sudo} tee /etc/apt/sources.list.d/docker.list > /dev/null
    ${__auto_sudo} apt-get update
    ${__auto_sudo} apt-get install -y docker-compose-plugin docker-buildx-plugin
    echo "Installed docker-compose-plugin"
    __old_compose=0
    __compose_upgraded=1
    if dpkg-query -W -f='${Status}' docker.io 2>/dev/null | grep -q "ok installed"; then
        ${__auto_sudo} apt-mark manual docker.io
    elif dpkg-query -W -f='${Status}' docker-ce 2>/dev/null | grep -q "ok installed"; then
        ${__auto_sudo} apt-mark manual docker-ce
    fi
    ${__auto_sudo} apt-get remove -y docker-compose
    echo "Removed docker-compose"
  else
    echo "${__project_name} does not know how to update Docker Compose on $__distro"
  fi
}


__check_compose_version() {
# Check for Compose V2 (docker compose) vs Compose V1 (docker-compose)
  if docker compose version >/dev/null 2>&1; then
    __compose_version=$($__docker_sudo docker compose version | sed -n -E -e "s/.*version [v]?([0-9.-]*).*/\1/ip")
    __compose_major=${__compose_version%%.*}
    __compose_minor=${__compose_version#*.}
    __compose_minor=${__compose_minor%%.*}
   if [[ "${__compose_major}" -eq 1 ]]; then
     __old_compose=1
   elif [[ "${__compose_minor}" -lt 18 ]]; then
     __old_compose=1
   else
     __old_compose=0
   fi
  else
    __old_compose=1
    __compose_version=$($__docker_sudo docker-compose --version | sed -n -E -e "s/.*version [v]?([0-9.-]*).*/\1/ip")
  fi
  if [ "${__old_compose}" -eq 1 ]; then
    if [ -n "${ETHDSECUNDO-}" ]  || [ ! "${__command}" = "update" ]; then # Don't run this twice
      echo
      if [[ "${__compose_major}" -eq 1 ]]; then
        echo "You are using docker-compose ${__compose_version}, which is unsupported by Docker, Inc."
        echo "${__project_name} only supports Compose V2."
        echo
        echo "It is recommended that you replace Compose V1 with Compose V2."
        while true; do
          read -rp "Do you want to update Docker Compose to V2? (yes/no) " __yn
          case $__yn in
            [Nn]* ) echo "Please be sure to update Docker Compose yourself!"; break;;
             * ) __upgrade_compose; break;;
          esac
        done
      else
        true  # Nothing now; maybe in future we'll do the update for the user
      fi
    fi
  fi
}


__prep_conffiles() {
# Create custom-prom.yml if it doesn't exist
  if [ ! -f "./prometheus/custom-prom.yml" ]; then
    ${__as_owner} touch "./prometheus/custom-prom.yml"
  fi
# Make sure the prometheus dir and its contents are accessible to user nobody
  if find prometheus -type d \! -perm 755 | grep -q .; then
    find prometheus -type d -exec chmod 755 {} \;
  fi
  if find prometheus -name '*.yml' \! -perm 664 | grep -q .; then
    find prometheus -name '*.yml' -exec chmod 664 {} \;
  fi
# Move ssv-config.yaml
  if [ -f "./ssv-config.yaml" ]; then
    ${__as_owner} mv ./ssv-config.yaml ssv-config/config.yaml
  fi
# Create config.yaml if it doesn't exist
  if [ ! -f "ssv-config/config.yaml" ]; then
    ${__as_owner} cp ssv-config/config-sample.yaml ssv-config/config.yaml
  fi
  if [ ! -f "ssv-config/dkg-config.yaml" ]; then
    ${__as_owner} cp ssv-config/dkg-config-sample.yaml ssv-config/dkg-config.yaml
  fi
# Make sure ssv-config yaml files are 664
  if find ssv-config -maxdepth 0 \! -perm 755 | grep -q .; then
    chmod 755 ssv-config
  fi
  if find ssv-config -name '*.yaml' \! -perm 664 | grep -q .; then
    chmod 664 ssv-config/*.yaml
  fi
# Make sure local user owns the dkg output dir and everything in it
  if find .eth/dkg_output \! -user "${OWNER}" -o \! -group "${OWNER_GROUP}" | grep -q .; then
    if [ "$__cannot_sudo" -eq 0 ]; then
      echo "Fixing ownership of .eth/dkg_output"
      ${__auto_sudo} chown -R "${OWNER}:${OWNER_GROUP}" .eth/dkg_output
      ${__auto_sudo} chmod -R 755 .eth/dkg_output
    else
      echo "Ownership of .eth/dkg_output should be fixed, but this user can't sudo"
    fi
  fi
# Make sure the dkg output dir and its contents are mod 0755
  if find .eth/dkg_output \! -perm 755 | grep -q .; then
    chmod -R 755 .eth/dkg_output
  fi
# Create cb-config.toml if it doesn't exist
  if [ ! -f "commit-boost/cb-config.toml" ]; then
    ${__as_owner} cp commit-boost/cb-config.toml.sample commit-boost/cb-config.toml
  fi
# Make sure local user owns .env
  if find . -name .env \! -user "${OWNER}" -o \! -group "${OWNER_GROUP}" | grep -q ./.env; then
    if [ "$__cannot_sudo" -eq 0 ]; then
      echo "Fixing ownership of .env"
      ${__auto_sudo} chown -R "${OWNER}:${OWNER_GROUP}" .env
      ${__auto_sudo} chmod -R 644 .env
      if [ -f .env.tmp ]; then
        ${__auto_sudo} rm -f .env.tmp
      fi
    else
      echo "Ownership of .env should be fixed, but this user can't sudo"
    fi
  fi
}


__check_for_snap() {
  if [[ "$__distro" = "ubuntu" && -n "$(command -v snap)" ]] && snap list 2>/dev/null | grep -qw 'docker'; then
    echo
    echo "WARNING! Snap Docker package detected. This WILL result in issues."
    echo "Removing the package will delete volumes and require a resync."
    echo
    echo "Doing so is still highly recommended however."
    echo
    echo "The exact steps depend a little on whether there already is an apt version of Docker installed as well,"
    echo "but in a nutshell \"$__me stop\" followed by \"sudo snap remove --purge docker\" followed by a reboot,"
    echo "and as needed install docker-ce or docker.io with apt."
    echo
    echo "Do join us on EthStaker Discord to work through this issue."
    echo
    echo "Aborting, this is not safe"
    exit 1
  fi
}


__install_bash_completions() {
  if [[ "$OSTYPE" = "darwin"* ]]; then
    echo "Skipping installation of tab completions (not supported on macOS)"
  else
    if [ ! -f "$(pkg-config --variable=completionsdir bash-completion)/ethd" ]; then
      echo "Installing bash completions for ethd"
      ${__auto_sudo} ln -s "$(dirname "$(realpath "${BASH_SOURCE[0]}")")/bash-completion" \
      "$(pkg-config --variable=completionsdir bash-completion)/ethd" || true
    fi
  fi
}


install() {
  if [ "$__cannot_sudo" -eq 1 ]; then
    echo "The install command requires the user to be part of the sudo group, or on macOS the admin group"
    exit 1
  fi
  if [[ "$__distro" = "ubuntu" ]]; then
    ${__auto_sudo} apt-get update
    ${__auto_sudo} apt-get install -y ca-certificates curl gnupg whiptail chrony pkg-config screen ncdu
    echo
    echo
    if [ -z "$(command -v docker)" ]; then
      if [ "${__os_major_version}" -lt 22 ]; then
        echo "${__project_name} cannot install Docker on Ubuntu ${__os_major_version}."
        echo "Consider upgrading to 22.04 and then 24.04."
        exit 1
      fi
      read -rp "This will attempt to install Docker and make your user part of the docker group. Do you wish to \
continue? (no/yes) " __yn
      case $__yn in
        [Yy]* ) ;;
        * ) echo "Aborting, no changes made"; return 0;;
      esac
      ${__auto_sudo} mkdir -p /etc/apt/keyrings
      ${__auto_sudo} curl -fsSL https://download.docker.com/linux/ubuntu/gpg | ${__auto_sudo} gpg --dearmor \
        --yes -o /etc/apt/keyrings/docker.gpg
      ${__auto_sudo} echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
        https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" \
        | ${__auto_sudo} tee /etc/apt/sources.list.d/docker.list > /dev/null
      ${__auto_sudo} apt-get update
      ${__auto_sudo} apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin \
        docker-buildx-plugin
      ${__auto_sudo} systemctl start systemd-logind
      echo "Installed docker-ce and docker-compose-plugin"
    else
      echo "Docker is already installed"
    fi
    __groups=$(${__as_owner} groups)
    if [[ ! "$__groups" =~ "docker" ]]; then
      echo "Making your user part of the docker group"
      ${__auto_sudo} usermod -aG docker "${OWNER}"
      echo "Please run newgrp docker or log out and back in"
    else
      echo "Your user is already part of the docker group"
    fi
  elif [[ "$__distro" =~ "debian" ]]; then
    ${__auto_sudo} apt-get update
    ${__auto_sudo} apt-get -y install ca-certificates curl gnupg whiptail chrony pkg-config screen ncdu
    echo
    echo
    if [ -z "$(command -v docker)" ]; then
      if [ "${__os_major_version}" -lt 11 ]; then
        echo "${__project_name} cannot install Docker on Debian ${__os_major_version}."
        echo "Consider upgrading to 11 and then 12."
        exit 1
      fi
      read -rp "This will attempt to install Docker and make your user part of the docker group. Do you wish to \
continue? (no/yes) " __yn
      case $__yn in
        [Yy]* ) ;;
        * ) echo "Aborting, no changes made"; return 0;;
      esac
      ${__auto_sudo} mkdir -p /etc/apt/keyrings
      ${__auto_sudo} curl -fsSL https://download.docker.com/linux/debian/gpg | ${__auto_sudo} gpg --dearmor \
        --yes -o /etc/apt/keyrings/docker.gpg
      ${__auto_sudo} echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
        https://download.docker.com/linux/debian $(lsb_release -cs) stable" \
        | ${__auto_sudo} tee /etc/apt/sources.list.d/docker.list > /dev/null
      ${__auto_sudo} apt-get update
      ${__auto_sudo} apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin \
        docker-buildx-plugin
      ${__auto_sudo} systemctl start systemd-logind
      echo "Installed docker-ce and docker-compose-plugin"
    else
      echo "Docker is already installed"
    fi
    __groups=$(${__as_owner} groups)
    if [[ ! "$__groups" =~ "docker" ]]; then
      echo "Making your user part of the docker group"
      ${__auto_sudo} usermod -aG docker "${OWNER}"
      echo "Please run newgrp docker or log out and back in"
    else
      echo "Your user is already part of the docker group"
    fi
  else
    echo "${__project_name} does not know how to install Docker on $__distro"
  fi

  if ! [[ "$__distro" = "ubuntu" ]] || [[ "$__distro" =~ "debian" ]]; then
    return 0
  fi

  # We only get here on Ubuntu or Debian
  __install_bash_completions
  __install_base=$(basename "$(dirname "$(realpath "${BASH_SOURCE[0]}")")")
  if [ "${__install_base}" = "eth-docker" ]; then
    read -rp "Do you want to be able to call 'ethd' from anywhere? (yes/no) " __yn
    case $__yn in
      [Nn]* ) return 0;;
      * ) ;;
    esac
    if grep -q "alias ethd" ~/.profile; then
      sed -i'.original' -e "/alias ethd/d" ~/.profile
    fi
    echo "alias ethd=$(realpath "${BASH_SOURCE[0]}")" >>~/.profile
    if grep -q "cat.*\.motd" ~/.profile; then
      sed -i'.original' -e "/cat.*\.motd/d" ~/.profile
    fi
    echo "cat $(dirname "$(realpath "${BASH_SOURCE[0]}")")/.motd" >>~/.profile
    echo "Go ahead and 'source ~/.profile' or log out and back in."
    echo "After that, you can use the command 'ethd'."
  fi

  return 0
}


__get_docker_free_space() { # set __free_space to what's available to Docker
  if [[ "$OSTYPE" = "darwin"* ]]; then # macOS doesn't expose docker root dir to the OS
    __free_space=$(__dodocker run --rm -v macos-space-check:/dummy busybox df -P /dummy | awk '/[0-9]%/{print $(NF-2)}')
  else
    __docker_dir=$(__dodocker system info --format '{{.DockerRootDir}}')
    __free_space=$(df -P "${__docker_dir}" | awk '/[0-9]%/{print $(NF-2)}')
  fi

  __regex='^[0-9]+$'
  if ! [[ "${__free_space}" =~ ${__regex} ]] ; then
    echo "Unable to determine free disk space. This is likely to be a bug."
    if [[ "$OSTYPE" = "darwin"* ]]; then
      echo "df reports $(__dodocker run --rm -v macos-space-check:/dummy busybox df -P /dummy) and __free_space is ${__free_space}"
    else
      echo "df reports $(df -P "${__docker_dir}") and __free_space is ${__free_space}"
    fi
    exit 70
  fi
}


__display_docker_dir() {
  if [[ "$OSTYPE" = "darwin"* ]]; then # macOS doesn't expose docker root dir to the OS
    echo "Here's total and used space on Docker's virtual volume"
    __dodocker run --rm -v macos-space-check:/dummy busybox df -h /dummy
  else
    echo "Here's total and used space on ${__docker_dir}"
    df -h "${__docker_dir}"
  fi
}


__display_docker_volumes() {
  echo
  if [ -z "$(__dodocker volume ls -q -f "name=^$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_[^_]+")" ]; then
    echo "There are no Docker volumes for this copy of ${__project_name}"
    echo
  else
    echo "Here are the Docker volumes used by this copy of ${__project_name} and their space usage:"
    __dodocker system df -v | grep -A 500 "VOLUME NAME" | grep -i "^$(basename "$(dirname "$(realpath "${BASH_SOURCE[0]}")")")"
    echo
    echo "If your Consensus Layer client takes more than 300 GiB, you can resync it with"
    echo "\"${__me} resync-consensus\"."
    echo
  fi
  if command -v ncdu >/dev/null 2>&1; then
    echo "If there is some mystery space being taken up, try \"sudo ncdu /\"."
  else
    echo "If there is some mystery space being taken up, install ncdu, then try \"sudo ncdu /\"."
    if [[ "$OSTYPE" == "darwin"* ]]; then
      echo "To install ncdu, run \"brew install ncdu\"."
    elif [[ "$__distro" = "ubuntu" || "$__distro" =~ "debian" ]]; then
      echo "To install ncdu, run \"sudo apt update && sudo apt install ncdu\"."
    else
      echo "How to install ncdu will be specific to your distribution ${__distro}."
    fi
  fi
  echo
}


space() {
  __get_docker_free_space
  echo
  if [[ "$OSTYPE" = "darwin"* ]]; then # macOS doesn't expose docker root dir to the OS
    echo "You have $(( __free_space / 1024 / 1024 )) GiB free for Docker volumes"
  else
    echo "You have $(( __free_space / 1024 / 1024 )) GiB free on ${__docker_dir}"
  fi
  echo
  __display_docker_dir
  __display_docker_volumes
}


# Warn user if space is low, so they can prune
__check_disk_space() {
  __get_docker_free_space

  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  __var="AUTOPRUNE_NM"
  __get_value_from_env "${__var}" "${__env_file}" "__auto_prune"
  __var="NETWORK"
  __get_value_from_env "${__var}" "${__env_file}" "NETWORK"

  if [ "${NETWORK}" = "mainnet" ] || [ "${NETWORK}" = "gnosis" ]; then
    __min_free=314572800
    __min_gib=300
    __safe_prune=250
  else
    __min_free=31457280
    __min_gib=30
    __safe_prune=25
  fi

# Literal match intended
# shellcheck disable=SC2076
  if [[ "${__value}" =~ "nethermind.yml" ]] && [[ "${__free_space}" -lt "${__min_free}" ]]; then
    echo
    echo "You are running Nethermind and have less than ${__min_gib} GiB of free disk space."
# shellcheck disable=SC2154
    if [ "${__auto_prune}" = true ]; then
      echo "It should currently be auto-pruning, check logs with \"$__me logs -f --tail 500 execution | grep \
Full\". Free space:"
    else
      echo "If the below reads above ${__safe_prune} GiB free, prune it with \"$__me prune-nethermind\""
    fi
    echo
    __display_docker_dir
    __display_docker_volumes
  elif [[ "${__value}" =~ "geth.yml" ]] && [[ "${__free_space}" -lt 104857600 ]]; then
    echo
    echo "You are running Geth and have less than 100 GiB of free disk space."
    echo "You may resync from scratch to use PBSS and slow on-disk DB growth, with \"$__me resync-execution\"."
    echo
    __display_docker_dir
    __display_docker_volumes
  elif [[ "${__value}" =~ "besu.yml" ]] && [[ "${__free_space}" -lt 52428800 ]]; then
    echo
    echo "You are running Besu and have less than 50 GiB of free disk space."
    echo
    echo "If this is a long-running Besu, you may prune trie-logs with \"$__me prune-besu\"."
    __display_docker_volumes
    echo
  elif [[ "${__free_space}" -lt 52428800 ]]; then
    echo
    echo "You have less than 50 GiB of free disk space:"
    echo
    __display_docker_dir
    echo
    echo "Pruning does not appear an option for your client mix."
    echo "If total space is less than 1.8 TiB, consider cloning to a larger drive."
    __display_docker_volumes
  fi
}


__source_build() {
# Check whether there's a source-built client and if so, force it with --no-cache
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"

  case "${__value}" in
    *deposit-cli.yml* )
      __var="DEPCLI_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
# shellcheck disable=SC2154
      if [ "${__build}" = "Dockerfile.source" ]; then
        __docompose --profile tools build --pull --no-cache deposit-cli-new
      fi
      ;;
  esac
  case "${__value}" in
    *mev-boost.yml* )
      __var="MEV_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache mev-boost
      fi
      ;;
  esac
  case "${__value}" in
    *reth.yml* )
      __var="RETH_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
    *geth.yml* )
      __var="GETH_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
    *besu.yml* )
      __var="BESU_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
    *nethermind.yml* )
      __var="NM_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
    *erigon.yml* )
      __var="ERIGON_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
    *nimbus-el.yml* )
      __var="NIMEL_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache execution
      fi
      ;;
  esac
  case "${__value}" in
    *lighthouse.yml* | *lighthouse-cl-only.yml* )
      __var="LH_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
    *teku.yml* | *teku-allin1.yml* | *teku-cl-only.yml* )
      __var="TEKU_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
    *lodestar.yml* | *lodestar-cl-only.yml* )
      __var="LS_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
    *nimbus.yml* | *nimbus-allin1.yml* | *nimbus-cl-only.yml* )
      __var="NIM_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
    *prysm.yml* | *prysm-cl-only.yml* )
      __var="PRYSM_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
    *grandine.yml* | *grandine-allin1.yml* | *grandine-cl-only.yml* )
      __var="GRANDINE_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
          __docompose build --pull --no-cache consensus
      fi
      ;;
  esac
  case "${__value}" in
    *vero-vc-only.yml* )
      __var="VERO_DOCKERFILE"
      __get_value_from_env "${__var}" "${__env_file}" "__build"
      if [ "${__build}" = "Dockerfile.source" ]; then
        __docompose build --pull --no-cache validator
      fi
      ;;
  esac
}


__migrate_compose_file() {
# When this gets called $__var is COMPOSE_FILE and $__value is what is set in .env for it
# Some files have been renamed and others removed altogether
  __from_yml=( xatu.yml )
  __to_yml=( contributoor.yml )

  IFS=":"
  set -o noglob
# Globbing is off
# shellcheck disable=SC2206
  __ymlarray=($__value) # split+glob with glob disabled, and split using : as delimiter
  set +o noglob
# Unset restores default
  unset IFS

  __value=""
  for __n in "${!__ymlarray[@]}"; do
    __ymlfile="${__ymlarray[__n]}"
    for __index in "${!__from_yml[@]}"; do
      if [ "${__from_yml[__index]}" = "${__ymlfile}" ]; then
        __ymlfile=${__to_yml[__index]}
        break
      fi
    done
    if [ -n "${__ymlfile}" ]; then
      if [ -z "${__value}" ]; then
        __value="${__ymlfile}"
      else
        __value="${__value}:${__ymlfile}"
      fi
    fi
  done
}


__ssv_switch() {
  echo "Detected legacy SSV Node. Migrating config to new testnet."
  echo
  echo "Stopping SSV Node container"
  __node=$(__dodocker ps --format '{{.Names}}' | grep 'ssv2-node')
  __dodocker stop "${__node}" && __dodocker rm -f "${__node}"
  __dodocker volume rm "$(__dodocker volume ls -q | grep -i "$(basename "$(realpath .)")"_ssv2-data)"
  echo
  echo "SSV Node stopped and database deleted."
  echo
  cp blox-ssv-config.yaml blox-ssv-config.yaml.bak
  cp blox-ssv-config.yaml ssv-config/config.yaml
  rm blox-ssv-config.yaml
  echo "Backup copy blox-ssv-config.yaml.bak created"
  echo "Making changes to ssv-config/config.yaml"
  __var="NETWORK"
  __get_value_from_env "${__var}" "${__env_file}" "NETWORK"
  sed -i'.original' 's/blox-ssv2.yml/ssv.yml/' "${__env_file}".source
  if ! grep -q "LogFilePath:" ssv-config/config.yaml; then
# macOS-isms: Newline for sed add
    sed -i'.original' '/global:/a\
  LogFilePath: /tmp/ssv/debug.log
' ssv-config/config.yaml
  fi
  if ! grep -q "MetricsAPIPort:" ssv-config/config.yaml; then
    sed -i'.original' '$a\
MetricsAPIPort: 15000
' ssv-config/config.yaml
  fi
  if ! grep -q "ssv:" ssv-config/config.yaml; then
    sed -i'.original' '/^  Network:/d' ssv-config/config.yaml # Remove old eth2 Network line if present
    sed -i'.original' '$a\
 ssv:
 ' ssv-config/config.yaml
    if [ "${NETWORK}" = "hoodi" ]; then
      sed -i'.original' '$a\
  Network: hoodi
' ssv-config/config.yaml
    elif [ "${NETWORK}" = "mainnet" ]; then
      sed -i'.original' '$a\
  Network: mainnet
' ssv-config/config.yaml
    else
      echo "${NETWORK} is not something that works with SSV."
      echo "Please fix this manually before running $__me update again."
      echo "Aborting."
      exit 1
    fi
  fi
  rm ssv-config/config.yaml.original
}


__delete_reth() {
# Check for Reth
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "reth.yml" ]]; then
    return 0
  fi

# Check Reth version, only continue if not on alpha
  __var="RETH_DOCKER_TAG"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ "${__value}" =~ "alpha" ]]; then
    return 0
  fi

  if [ -z "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]reth-el-data")" ]; then # No Reth volume
    return 0
  fi

# Has db been initialized?
  __db_exists=$(__dodocker run --rm -v "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]reth-el-data")":"/var/lib/reth" \
      alpine:3 sh -c 'if [ -f "/var/lib/reth/db/database.version" ]; then echo true; else echo false; fi')
  if [ "$__db_exists" = "false" ]; then
    return 0
  fi

# Check Reth db version
  __db_version="$(__dodocker run --rm -v "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]reth-el-data")":"/var/lib/reth" \
      alpine:3 cat /var/lib/reth/db/database.version)"
  if [ "${__db_version}" -ne "1" ]; then
    return 0
  fi

  echo "Detected Reth. For Reth beta, it will need to be re-synced from scratch."
  echo
  if [ "${__non_interactive:-0}" -eq 0 ]; then
    while true; do
      read -rp "WARNING - About to delete the Reth database. Do you wish to continue? (Y/n) " __yn
      case $__yn in
        [Nn]o | [Nn]  ) echo "No changes made"; return 0;;
        * ) break;;
      esac
    done
  fi

  echo "Stopping Reth container"
  __docompose stop execution && __docompose rm -f execution
  __dodocker volume rm "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]reth-el-data")"
  echo
  echo "Reth stopped and database deleted."
  echo
}


__delete_erigon() {
# Check for Erigon
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "erigon.yml" ]]; then
    return 0
  fi

# Check Erigon version, only continue if v3
  __var="ERIGON_DOCKER_TAG"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  __var="ERIGON_DOCKER_REPO"
  __get_value_from_env "${__var}" "${__env_file}" "__repo"
  if [[ "${__value}" =~ ^(v?2\.).* ]]; then
    return 0
  fi

  if [ -z "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]erigon-el-data")" ]; then # No Erigon volume
    return 0
  fi

# Detect Erigon v3 by directory caplin/latest
  __erigon_v3=$(__dodocker run --rm -v "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]erigon-el-data")":"/var/lib/erigon" \
      alpine:3 sh -c 'if [ -d "/var/lib/erigon/caplin/latest" ]; then echo true; else echo false; fi')
  if [ "$__erigon_v3" = "true" ]; then
    return 0
  fi

  echo "Detected Erigon. For Erigon v3, it will need to be re-synced from scratch."
  echo
  while true; do
    read -rp "WARNING - About to delete the Erigon database. Do you wish to continue? (Y/n) " __yn
    case $__yn in
      [Nn]o | [Nn]  ) echo "Aborting, no changes made"; exit 130;;
      * ) break;;
    esac
  done

  echo "Stopping Erigon container"
  __docompose stop execution && __docompose rm -f execution
  __dodocker volume rm "$(__dodocker volume ls -q -f "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]erigon-el-data")"
  echo
  echo "Erigon stopped and database deleted."
  echo
}


__upgrade_postgres() {
# Check for web3signer
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "web3signer.yml" ]]; then
    return 0
  fi

  __source_vol="$(basename "$(pwd)" | tr '[:upper:]' '[:lower:]')_web3signer-slashing-data"
  if [ -z "$(__dodocker volume ls -q -f "name=${__source_vol}")" ]; then
    return 0
  fi

  __during_postgres=1

  __source_pg="$(__dodocker run --rm -v "${__source_vol}":"/var/lib/postgresql/data" \
    alpine:3 cat /var/lib/postgresql/data/PG_VERSION)"

  if [ "${__source_pg}" -lt "${__target_pg}" ]; then
    echo "Web3signer is using PostgreSQL ${__source_pg}. The current version is PostgreSQL ${__target_pg}."
    echo
    if [ "${__non_interactive:-0}" -eq 0 ]; then
      while true; do
        read -rp "Would you like to migrate to PostgreSQL ${__target_pg}? (Y/n) " __yn
        case $__yn in
          [Nn]o | [Nn]  ) echo "Keeping PostgreSQL at version ${__source_pg}"; return 0;;
          * ) break;;
        esac
      done
    fi
  else
    return 0
  fi

  __source_size="$(__dodocker run --rm -v "${__source_vol}":"/var/lib/postgresql/data" \
    alpine:3 du -s /var/lib/postgresql/data/ | awk '{print $1}')"

  __regex='^[0-9]+$'
  if ! [[ "${__source_size}" =~ ${__regex} ]] ; then
    echo "Unable to determine database size. This is likely a bug."
    echo "__source_size is ${__source_size}"
    return 70
  fi

  __get_docker_free_space

  if [[ "${__free_space}" -lt $(( (__source_size * 2) + 10485760 )) ]]; then
    echo
    echo "You don't have enough free space to migrate the database."
    echo "It is $(( __source_size / 1024 / 1024 )) GiB in size and you need twice as much free again."
    echo
    __display_docker_dir
    echo
    return
  fi

  __backup_vol="$(basename "$(pwd)" | tr '[:upper:]' '[:lower:]')_web3signer-slashing-data-pg${__source_pg}-backup"

  echo "Stopping Web3signer"
  __docompose stop web3signer && __docompose rm -f web3signer
  echo "Stopping PostgreSQL"
  __docompose stop postgres && __docompose rm -f postgres

  echo "Copying data in web3signer-slashing-data volume to backup"
  __dodocker volume create "${__backup_vol}"
  __dodocker run --rm -v "${__source_vol}":"/var/lib/postgresql/data" \
    -v "${__backup_vol}":"/var/lib/postgresql/${__source_pg}/data" \
    alpine:3 cp -a /var/lib/postgresql/data/. "/var/lib/postgresql/${__source_pg}/data/"

  echo
  echo "Migrating database from PostgreSQL ${__source_pg} to PostgreSQL ${__target_pg}"
  echo "If this step fails, the Web3signer slashing protection database is no longer protecting you."
  echo "In failure case, do not start Web3signer again, instead seek help on Ethstaker Discord."
  echo

  __dodocker pull "pgautoupgrade/pgautoupgrade:${__target_pg}-bookworm"
  __during_migrate=1
  __dodocker run --rm -v "${__source_vol}":"/var/lib/postgresql/data" \
   -e PGAUTO_ONESHOT=yes -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres \
   "pgautoupgrade/pgautoupgrade:${__target_pg}-bookworm"

  __migrated=1

  echo
  echo "Adjusting PostgreSQL Docker tag"
  if [ ! -f "${__env_file}.source" ]; then # update() didn't migrate env, let's make sure .env.source exists
    cp "${__env_file}" "${__env_file}.source"
  fi
  __var="PG_DOCKER_TAG"
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
  PG_DOCKER_TAG=${__target_pg}-bookworm # To bookworm to avoid collation errors - also a faster PostgreSQL
  __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  echo "Web3signer has been stopped. You'll need to run \"${__me} update\" and \"${__me} up\" to start it again."
  echo
  echo "A copy of your old slashing protection database is in the Docker volume ${__backup_vol}."
  echo "Confirm that everything works, and then delete it with \"docker volume rm ${__backup_vol}\"."
  __during_postgres=0
}


__lookup_cf_zone() { # Migrates traefik-cf setup to use Zone ID
  __get_value_from_env "COMPOSE_FILE" "${__env_file}.source" "__compose_ymls"
  __get_value_from_env "CF_DNS_API_TOKEN" "${__env_file}.source" "__dns_token"
  __get_value_from_env "CF_ZONE_API_TOKEN" "${__env_file}.source" "__zone_token"
  __get_value_from_env "DOMAIN" "${__env_file}.source" "__domain"
# shellcheck disable=SC2154
  if [[ ! $__compose_ymls =~ traefik-cf.yml ]]; then
    __value=""
    return
  elif [[ -n $__dns_token ]]; then
    if [[ -n $__zone_token ]]; then
      __token=$__zone_token
    else
      __token=$__dns_token
    fi
    set +e
    __value=$(__docompose run --rm curl-jq sh -c \
      "curl -s \"https://api.cloudflare.com/client/v4/zones?name=${__domain}\" -H \"Authorization: Bearer ${__token}\" \
      -H \"Content-Type: application/json\" | jq -r '.result[0].id'" | tail -n 1)
    __code=$?
    if [[ "$__code" -ne 0 ]]; then
      __value=""
      return
    fi
    __success=$(__docompose run --rm curl-jq sh -c \
      "curl -s \"https://api.cloudflare.com/client/v4/zones?name=${__domain}\" -H \"Authorization: Bearer ${__token}\" \
      -H \"Content-Type: application/json\" | jq -r '.success'" | tail -n 1)
    set -e
    if [ "${__success}" = "true" ]; then
      return
    else
      __value=""
      return
    fi
  else
    __value=""
    return
  fi
}


__enable_v6() {
  if [ "${__docker_major_version}" -lt 27 ]; then
    return
  fi

  __var="IPV6"
  __get_value_from_env "${__var}" "${__env_file}" "IPV6"
  if [ "${IPV6}" = "true" ]; then
    return
  fi

  echo "Testing IPv6 host connectivity"
  if ! ping -c1 2001:4860:4860::8888 >/dev/null; then
    echo "No IPv6 detected; continuing with IPv4"
    return
  fi

  echo "Testing IPv6 Docker connectivity"
  __dodocker network create --ipv6 ip6net_ethd_test
  __v6_works=$(__dodocker run --rm --network ip6net_ethd_test busybox sh -c \
    "if ping -c1 -6 2001:4860:4860::8888 >/dev/null; then echo true; else echo false; fi")
  __dodocker network rm ip6net_ethd_test

  if [ "${__v6_works}" = "true" ]; then
    echo "Enabling IPv4/6 dual-stack for your Eth Docker setup"
    IPV6="true"
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
    __enabled_v6=1
  else
    echo "Docker cannot use IPv6; continuing with IPv4"
  fi
}


__get_value_from_env() {
  # Call with variable name to read, env file name, and global variable to assign the value to
  # Also sets global __found
    local __var_name="$1"
    local __env_file="$2"
    local __output_var="$3"
    local __output
    local __parsed_value

    if [[ "${__output_var}" = "__parsed_value" || "${__output_var}" = "__output_var" \
        || "${__output_var}" = "__output" || "${__output_var}" = "__env_file" \
        || "${__output_var}" = "__var_name" ]]; then
      echo "__get_value_from_env was called with a conflicting output variable: $__output_var"
      echo "This is a bug."
      exit 70
    fi

    __output=$(awk -v var="$__var_name" '
        BEGIN { __found = 0; __value = "" }

        # Skip empty lines and comments
        /^#|^\s*$/ {
            next
        }

        # Match single-line unquoted value
        $0 ~ "^[ \t]*"var"=[^\"].*$" {
            gsub("^[ \t]*"var"=", "")
            gsub(/^[ \t]*|[ \t]*$/, "", $0)
            __value = $0
            __found = 1
            exit
        }

        # Match empty unquoted value
        $0 ~ "^[ \t]*"var"=$" {
            __value = ""
            __found = 1
            exit
        }

        # Match a quoted single-line value
        $0 ~ "^[ \t]*"var"=\"[^\"]*\"[ \t]*$" {
            gsub("^[ \t]*"var"=\"", "")
            gsub(/"[ \t]*$/, "", $0)
            __value = "\"" $0 "\""
            __found = 1
            exit
        }

        # Match the start of a multi-line value (with opening quote)
        $0 ~ "^[ \t]*"var"=\"[^\"]*$" {
            gsub("^[ \t]*"var"=\"", "")
            __value = "\"" $0 "\n"
            __found = 1
            next
        }

        # Continue collecting lines for a multi-line value
        __found && !/"[ \t]*$/ {
            __value = __value $0 "\n"
            next
        }

        # End of a multi-line value (with closing quote)
        __found && /"[ \t]*$/ {
            gsub(/[ \t]*"[ \t]*$/, "")
            __value = __value $0 "\""
            __found = 1
            exit
        }

        END {
            # Print here-doc style so we can parse with awk
            # Print the value as is, including quotes for multi-line
            print "__value<<EOF"
            print __value
            print "EOF"
            print "__found=" __found
        }
    ' "$__env_file")

    # Parse __value using here-doc style
    __parsed_value=$(awk '/^__value<<EOF$/ {getline; while ($0 != "EOF") { print; getline } }' <<< "$__output")
    # Parse __found directly into a global variable
    __found=$(awk -F= '/^__found=/ {print $2}' <<< "$__output")

    # assign value to caller’s variable
    printf -v "$__output_var" '%s' "$__parsed_value"
}


__update_value_in_env() {
# Call as __update_value_in_env "${__var}" "${__value}" "${__env_file}"
    local __var_name="$1"
    local __new_value="$2"
    local __env_file="$3"

    # Escape backslashes for safety
    local __escaped_value
    __escaped_value=$(printf '%s' "${__new_value}" | sed 's/\\/\\\\/g')

    # Check if the variable already exists in the .env file
    if grep -q "^[ \t]*${__var_name}=" "${__env_file}"; then
        # Variable exists, update it
        awk -v var="${__var_name}" -v new_value="${__escaped_value}" '
            BEGIN { in_block = 0; multi_line = 0 }

            # Match the line that starts with the variable name
            $0 ~ "^[ \t]*" var "=" {
                # If the value starts with a quote, it may be a multi-line
                if ($0 ~ "^[ \t]*" var "=\"") {
                    # Start of multi-line value
                    multi_line = 1
                    # Print the variable name with the new value, replacing & safely
                    gsub(/&/, "\\&", new_value)
                    print var "=" new_value
                } else {
                    # Single-line value
                    gsub(/&/, "\\&", new_value)
                    print var "=" new_value
                }
                # Set the flag to indicate we are processing the target variable block
                in_block = 1
                next
            }

            # If we encounter a new variable definition, stop skipping lines
            /^[A-Z_][A-Z0-9_]*=/ && in_block {
                in_block = 0
                multi_line = 0
            }

            # Continue to skip lines in a multi-line block if multi_line is true
            multi_line && !/"[ \t]*$/ {
                next
            }

            # If we reach the end of a multi-line value, reset flags
            multi_line && /"[ \t]*$/ {
                in_block = 0
                multi_line = 0
                next
            }

            # Print all lines if not in the target variable block
            { print }
        ' "${__env_file}" | ${__as_owner} tee "${__env_file}.tmp" >/dev/null
        ${__as_owner} mv "${__env_file}.tmp" "${__env_file}"
    else
        # Variable does not exist, append it
        printf "%s=%s\n" "${__var_name}" "${__escaped_value}" | ${__as_owner} tee -a "${__env_file}" >/dev/null
    fi
}


__env_migrate() {
  if [ ! -f "${__env_file}" ]; then
    return 0
  fi

  __old_vars=( XATU_KEY ERIGON_P2P_PORT_2 OBOL_EL_NODE ARCHIVE_NODE RAPID_SYNC_URL MINIMAL_NODE \
    CHARON_VERSION VALIDATOR_EJECTOR_VERSION LIDO_DV_EXIT_VERSION )
  __new_vars=( CONTRIBUTOOR_USERNAME EL_P2P_PORT_2 EL_RPC_NODE EL_ARCHIVE_NODE CHECKPOINT_SYNC_URL CL_MINIMAL_NODE \
    CHARON_TAG VALIDATOR_EJECTOR_TAG LIDO_DV_EXIT_TAG )

  if [ "${__debug}" -eq 1 ]; then  # Find any values in default.env that contain dashes
    __error=0
    while IFS= read -r __line; do
      # Skip blank lines and comments
      [[ -z "${__line}" || "${__line}" =~ ^# ]] && continue

      # Warn on dash-containing variable names
      if [[ "${__line}" =~ ^([A-Za-z0-9_-]+)= ]]; then
        __varname="${BASH_REMATCH[1]}"
        if [[ "${__varname}" = *-* ]]; then
          echo "❌ Error: Variable '${__varname}' contains a dash and would not be usable in Bash."
          (( ++__error ))
        fi
        if [[ "${__varname}" = "ENV_VERSION" ]]; then
          continue
        fi
      else
        continue  # Doesn't match variable assignment format
      fi
    done < "./default.env"
    if [ "${__error}" -gt 0 ]; then
      exit 1
    fi
  fi

# Always make sure we have a SIREN password
  __var="SIREN_PASSWORD"
  __get_value_from_env "${__var}" "${__env_file}" "SIREN_PASSWORD"
  if [ -z "${SIREN_PASSWORD}" ]; then
    SIREN_PASSWORD=$(head -c 8 /dev/urandom | od -A n -t u8 | tr -d '[:space:]' | sha256sum | head -c 32)
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  fi

  __var=ENV_VERSION
  __get_value_from_env "${__var}" "default.env" "__target_ver"
  __get_value_from_env "${__var}" "${__env_file}" "__source_ver"
# Aggressive prune to work around Docker grabbing old clients. Here so it doesn't get called during config
# shellcheck disable=SC2154
  if [[ "${__source_ver}" -lt "9" ]]; then
    __dodocker system prune --force -a
  fi

# shellcheck disable=SC2154
  if [[ "${__keep_targets}" -eq 1 && "${__target_ver}" -le "${__source_ver}" ]]; then # No changes in template, do nothing
    return 0
  fi

  if [ "${__keep_targets}" -eq 0 ]; then
    echo "Refreshing build targets in ${__env_file}"
  fi
  if [[ "${__target_ver}" -gt "${__source_ver}" ]]; then
    echo "Migrating ${__env_file} to version ${__target_ver}"
  fi

  ${__as_owner} cp "${__env_file}" "${__env_file}".source
  __during_migrate=1
  __migrated=1
  ${__as_owner} cp default.env "${__env_file}"

  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}.source" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ "${__value}" =~ "blox-ssv2.yml" ]]; then
    __ssv_switch
  fi

  # Migrate over user settings
  while IFS= read -r __line; do  # read default.env and process all variables in it
    # Skip blank lines and comments
    [[ -z "${__line}" || "${__line}" =~ ^# ]] && continue

    if [[ "${__line}" =~ ^([A-Za-z0-9_-]+)= ]]; then
      __var="${BASH_REMATCH[1]}"
    else
      continue  # Doesn't match variable assignment format
    fi
    if [[ "${__var}" = "ENV_VERSION" ]]; then
      continue
    fi

    __get_value_from_env "${__var}" "${__env_file}.source" "__value"
    if [ "${__found}" -eq 1 ]; then  # Only if variable isn't new in default.env
      if [ "${__var}" = "COMPOSE_FILE" ]; then
        __migrate_compose_file
      fi
      if [[ "${__source_ver}" -lt "17" && "${__var}" = "IPV6" ]]; then  # One-time attempt; remove after Pectra
        __enable_v6
        if [ "${__enabled_v6}" -eq 1 ]; then
          __value="true"
        fi
      fi
      if [[ "${__source_ver}" -lt "18" && "${__var}" = "OBOL_CHARON_CL_ENDPOINTS" ]]; then
        __get_value_from_env "OBOL_CL_NODE" "${__env_file}.source" "_obol_cl_node"
        if [ -n "${__obol_cl_node}" ]; then
          __value="${__obol_cl_node}"
          echo "Set OBOL_CHARON_CL_ENDPOINTS to ${__value}"
        fi
      fi
      if [ "${__var}" = "CL_QUIC_PORT" ]; then
        __get_value_from_env "CL_P2P_PORT" "${__env_file}.source" "__cl_port"
        if [ -n "${__cl_port}" ] && [ "${__cl_port}" = "${__value}" ]; then
          __value=$((__value + 1))
          echo "Adjusted CL_QUIC_PORT to ${__value} so it does not conflict with CL_P2P_PORT"
        fi
        __get_value_from_env "PRYSM_UDP_PORT" "${__env_file}.source" "__prysm_port"
        if [ -n "${__prysm_port}" ] && [ "${__prysm_port}" = "${__value}" ]; then # just in case this is one ahead
          __value=$((__value + 1))
          echo "Adjusted CL_QUIC_PORT to ${__value} so it does not conflict with PRYSM_UDP_PORT"
        fi
      fi
# Literal match intended
# shellcheck disable=SC2076
      if [[ "${__var}" = "CHECKPOINT_SYNC_URL" && "${__value}" =~ "eth2-beacon-mainnet.infura.io" ]]; then
        __value="https://beaconstate.info"
      fi
      if [[ "${__var}" = "HOST_IP" && "${__value: -1}" = ":" ]]; then
        __value="${__value%:}" # Undo Compose V1 accommodation
      fi
      if [[ "${__var}" = "SHARE_IP" && "${__value: -1}" = ":" ]]; then
        __value="${__value%:}" # Undo Compose V1 accommodation
      fi
      if [ "${__var}" = "CF_ZONE_ID" ]; then
        __lookup_cf_zone
        if [ -n "${__value}" ]; then
          __update_value_in_env "${__var}" "$__value" "${__env_file}"
        fi
      fi
      if [[ "${__keep_targets}" -eq 0 && "$__var" =~ (_TAG|_REPO|_TARGET|_DOCKERFILE)$ ]]; then
        __get_value_from_env "${__var}" "default.env" "__value" # Reset build target to default.env value
      else
        if [[ "${__var}" = "DDNS_TAG" && "${__source_ver}" -lt "8" ]]; then # Switch to ddns-updater
          __value="v2"
        fi
        if [[ "${__var}" = "LH_DOCKER_TAG" && "${__value}" = "latest-modern" ]]; then # LH 5.2 ditched latest-modern
          __value="latest"
        fi
        if [[ "${__var}" = "ERIGON_DOCKER_TAG" && "${__value}" = "stable" ]]; then # Erigon switched to latest
          __value="latest"
        fi
        if [[ "${__var}" = "ERIGON_DOCKER_REPO" && "${__value}" = "thorax/erigon" ]]; then # Erigon new repo
          __value="erigontech/erigon"
        fi
        if [[ "${__var}" = "PRYSM_DOCKER_REPO" && "${__value}" = "gcr.io/prysmaticlabs/prysm/beacon-chain" ]]; then  # Prysm new repo
          __value="gcr.io/offchainlabs/prysm/beacon-chain"
        fi
        if [[ "${__var}" = "PRYSM_DOCKER_VC_REPO" && "${__value}" = "gcr.io/prysmaticlabs/prysm/validator" ]]; then  # Prysm new repo
          __value="gcr.io/offchainlabs/prysm/validator"
        fi
        if [[ "${__var}" = "PRYSM_DOCKER_CTL_REPO" && "${__value}" = "gcr.io/prysmaticlabs/prysm/cmd/prysmctl" ]]; then  # Prysm new repo
          __value="gcr.io/offchainlabs/prysm/cmd/prysmctl"
        fi
        if [[ "${__var}" = "PRYSM_DOCKER_CTL_TAG" && "${__value}" = "latest" && "${__source_ver}" -lt "34" ]]; then  # Prysm new stable ctl tag
          __value="stable"
        fi
        if [[ "${__var}" = "BESU_DOCKER_TAG" && ( "${__value}" =~ "latest-openjdk" || "${__value}" =~ "latest-openj9" || "${__value}" =~ "latest-graalvm" ) ]]; then  # Besu switched to latest
          __value="latest"
        fi
        if [[ "${__var}" = "SSV_NODE_REPO" && "${__value}" = "bloxstaking/ssv-node" ]]; then # SSV new repo
          __value="ssvlabs/ssv-node"
        fi
        if [[ "${__var}" = "DEPCLI_SRC_REPO" && "${__source_ver}" -lt "21" ]]; then
          __value="https://github.com/eth-educators/ethstaker-deposit-cli"
        fi
        if [[ "${__var}" = "DEPCLI_DOCKER_TAG" && "${__value}" = "nonesuch" ]]; then
          __value="latest"
        fi
      fi
      # Handle & in GRAFFITI gracefully, as well as multi-line
      __update_value_in_env "${__var}" "$__value" "${__env_file}"
    fi
  done < "./default.env"

  # Move value from old variable name(s) to new one(s)
  for __index in "${!__old_vars[@]}"; do
    __var=${__old_vars[__index]}
    __get_value_from_env "${__var}" "${__env_file}.source" "__value"
    if [ "${__found}" -eq 1 ]; then
      if [[ "${__source_ver}" -lt "23" && "${__var}" = "XATU_KEY" ]]; then
        __xatu_decode="$(base64 -d <<< "${__value}")"
        __user="${__xatu_decode%%:*}"
        __password="${__xatu_decode#*:}"
        __value="${__user}"  # Is updated in .env after this if section
        __update_value_in_env "CONTRIBUTOOR_PASSWORD" "$__password" "${__env_file}"
      fi
      __update_value_in_env "${__new_vars[__index]}" "$__value" "${__env_file}"
    fi
  done
  # Check whether we run a CL or VC, if so nag about FEE_RECIPIENT
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  # It's CL&VC, CL-only, or VC-only
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ "${__value}" =~ "prysm.yml" || "${__value}" =~ "lighthouse.yml" || "${__value}" =~ "teku.yml" \
    || "${__value}" =~ "nimbus.yml" || "${__value}" =~ "lodestar.yml" || "${__value}" =~ "-cl-only.yml" \
    || "${__value}" =~ "-allin1.yml" || "${__value}" =~ "-vc-only.yml" ]]; then
    # Check for rewards
    __var="FEE_RECIPIENT"
    __get_value_from_env "${__var}" "${__env_file}" "__value"
    if [[ -z "${__value}" || ${__value} != 0x* || ${#__value} -ne 42 ]]; then
      if [ "${__non_interactive:-0}" -eq 0 ]; then
        whiptail --msgbox "A fee recipient ETH wallet address is required in order to start the client. This is \
  for priority fees and, optionally, MEV. Please enter a valid ETH address in the next screen. Refer to \
  Eth Docker docs (https://ethdocker.com/About/Rewards) for more information.\n\nCAUTION: \"$__me up\" will fail if no \
  valid address is set" 12 75
        __query_coinbase
        __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
      else
        echo "A fee recipient ETH wallet address is required in order to start the client. Please set one in \".env\"."
        echo "CAUTION: \"$__me up\" will fail if no valid address is set."
      fi
    fi
  fi

  __during_migrate=0
  echo "${__env_file} updated successfully"
}


__nag_os_version() {
  if [[ "$__distro" = "ubuntu" ]]; then
    if [ "${__os_major_version}" -lt 22 ]; then
     echo
     echo "Ubuntu ${__os_major_version} is older than the recommended 24.04 or 22.04 version."
     echo
     echo "Updating is neither urgent nor required, merely recommended."
     echo
     echo "Guide to upgrading to 24.04: https://gist.github.com/yorickdowne/94f1e5538007f4c9d3da7b22b0dc28a4"
    fi
  fi

  if [[ "$__distro" =~ "debian" ]]; then
    if [ "${__os_major_version}" -lt 11 ]; then
     echo
     echo "Debian ${__os_major_version} is older than the recommended 12 or 11 version."
     echo
     echo "Updating is neither urgent nor required, merely recommended."
     echo
     echo "Guide to upgrading to 12: https://gist.github.com/yorickdowne/ec9e2c6f4f8a2ee93193469d285cd54c"
    fi
  fi
}


__pull_and_build() {
  echo "Building local client images"
  __dodocker system prune --force
  __docompose --profile tools pull
  __source_build
  __docompose --profile tools build --pull
}


# Arguments are passed, but shellcheck doesn't recognize that
# shellcheck disable=SC2120
update() {
# Only one copy of update() should run per Eth Docker stack
  local __script_dir
  __script_dir="$(dirname "$(realpath "${BASH_SOURCE[0]}")")"
  local __uniq_id="${__script_dir//\//_}"
  local __lock_file="${__uniq_id}_lock"
  ${__as_owner} touch "/tmp/${__lock_file}"
  exec 200<"/tmp/${__lock_file}"
  if ! flock -n 200; then
      echo "Another instance of \"${__me} update\" is running. Aborting."
      exit 1
  fi

  __during_update=1
  __enabled_v6=0  # Remove after Pectra

  if [[ $(${__as_owner} git status --porcelain) ]]; then
    __dirty=1
  else
    __dirty=0
  fi

  __free_space=$(df -P "$(pwd)" | awk '/[0-9]%/{print $(NF-2)}')

  __regex='^[0-9]+$'
  if ! [[ "${__free_space}" =~ ${__regex} ]] ; then
    echo "Unable to determine free disk space. This is likely a bug."
    echo "df reports $(df -P "$(pwd)") and __free_space is ${__free_space}"
    exit 70
  elif [ "$(df -P "$(pwd)" | awk '/[0-9]%/{print $(NF-2)}')" -lt 1024 ]; then
    echo "You have less than 1 MiB of space left on $(pwd)."
    echo "Aborting, as an update is not safe."
    exit 1
  fi

  __get_docker_free_space
  if [ "${__free_space}" -lt 1048576 ]; then
    echo "You have less than 1 GiB of space left for Docker volumes."
    echo "Aborting, as an update is not safe."
    exit 1
  fi

# This is long-running, and it's better if we're in a protected session if interactive
  if [[ -z "${STY:-}" && -z "${TMUX:-}" && ! "$*" =~ "--non-interactive" && ! "${ETHD_FRONTEND:-}" = "noninteractive" ]]; then
    local __no_screen_cmd=0
    echo "\"${__me} update\" benefits from running in a session that protects it against disconnects."
    if [ -z "$(command -v screen)" ]; then
      if [[ "__cannot_sudo" -eq 0 && ("$__distro" = "ubuntu" || "$__distro" = "debian") ]]; then
        echo "Installing screen"
        ${__auto_sudo} apt-get update && ${__auto_sudo} apt-get -y install screen
      else
        echo "\"screen\" command not found, continuing as-is"
        __no_screen_cmd=1
      fi
    fi
    if [ "$__no_screen_cmd" -eq 0 ]; then
      local __screen_session="${__uniq_id}"
# Find old lingering screen sessions and close them
      local __old_sessions
      set +e
      __old_sessions=$(screen -ls 2>/dev/null | awk -v name="${__screen_session}" -v status="Detached" '$0 ~ name && $0 ~ status {print $1}')
      set -e
      if [ -n "${__old_sessions}" ]; then
        local __session_id
        echo "Closing old, detached screen sessions"
        while IFS= read -r __session_id; do
          if [ -n "${__session_id}" ]; then
            echo "Closing screen session ${__session_id}"
            screen -S "${__session_id}" -X quit
          fi
        done <<< "$__old_sessions"
        echo
      fi
# Screen should run with login shell so that .profile gets loaded and aliases work
      if [[ ! -f "${HOME}/.screenrc" ]] || ! grep -q 'shell' "${HOME}/.screenrc"; then
# Intentional, I want this verbatim
# shellcheck disable=SC2016
        echo 'shell -$SHELL' >>"${HOME}/.screenrc"
      fi
      echo "Starting a new screen session with identifier ${__screen_session}"
      echo "If you get disconnected, reconnect with \"screen -r ${__screen_session}\""
      echo "A log of the update run can be found in \"/tmp/${__screen_session}.log\""
      exec 200<&-
# Launch a new detached screen session and attach to it.
# Use bash -c to run 'ethd update', and pass along "$@"
#
#     ${BASH_SOURCE[0]} update "\$@"; exec bash
#   Escape \$@ so the outer shell doesn't expand it. Inner shell expands it.
#
#   "dummy" becomes $0 in the inner shell; "$@" parameters are assigned to $1, $2, etc.
#
#   exec bash replaces bash -c , so that the user is still inside screen at the end
#
      screen -S "${__screen_session}" -L -Logfile "/tmp/${__screen_session}.log" -dma bash -c "${BASH_SOURCE[0]} update \"\$@\"; exec bash --login" dummy "$@"
      screen -RR "${__screen_session}"
      exit 0
    fi
  fi

  if [ -z "${ETHDSECUNDO-}" ]; then
    set +e
    ${__as_owner} git config pull.rebase false
    __var="ETH_DOCKER_TAG"
    __get_value_from_env "${__var}" "${__env_file}" "__value"
    if [ -z "${__value}" ] || [ "${__value}" = "latest" ]; then
      export ETHDPINNED=""
      __branch=$(git rev-parse --abbrev-ref HEAD)
      if [[ "${__branch}" =~ ^tag-* ]]; then
        git checkout main
      fi
# This preps for a change of ext-network.yml in a future update, after Pectra
      ${__as_owner} cp ext-network.yml ext-network.yml.bak
      ${__as_owner} git update-index --no-assume-unchanged ext-network.yml
      DOCKER_EXT_NETWORK=$(${__as_owner} sed -n 's/^\s*name:\s*\(.*\)/\1/p' ext-network.yml)
# I mean this literally
# shellcheck disable=SC2016
      if [ ! "${DOCKER_EXT_NETWORK:-"rocketpool_net"}" = '${DOCKER_EXT_NETWORK}' ]; then
        __var=DOCKER_EXT_NETWORK
        __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
      fi
      ${__as_owner} git restore ext-network.yml
# End ext-network prep
      ${__as_owner} git pull origin main
    else
      export ETHDPINNED="${__value}"
      ${__as_owner} git fetch --tags
      ${__as_owner} git checkout -B "tag-${__value}" "tags/${__value}"
    fi
    export GITEXITCODE=$?
    set -e
    # BASH_SOURCE so newer code gets to do the update. Use an ENV var
    # to avoid infinite loop
    export ETHDSECUNDO=1
    exec "${BASH_SOURCE[0]}" update "$@"
  fi

# This part changes in a future post-Pectra update, it gets executed on the second run of update
# For now, change nothing
  if [ -f "ext-network.yml.bak" ]; then
    ${__as_owner} cp ext-network.yml.bak ext-network.yml
    ${__as_owner} rm ext-network.yml.bak
  fi
  ${__as_owner} git update-index --assume-unchanged ext-network.yml
  if [ -f "ext-network.yml.original" ]; then
    ${__as_owner} rm ext-network.yml.original
  fi

  __keep_targets=1
  __debug=0
  __targetcli=""
  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --keep-targets)
        if [ -n "${__targetcli}" ]; then
          echo "Error: --keep-targets and --refresh-targets cannot be used together; use either option once only"
          exit 1
        fi
        __keep_targets=1
        __targetcli="--keep-targets"
        shift
        ;;
      --refresh-targets | --reset-targets)
        if [ -n "${__targetcli}" ]; then
          echo "Error: --keep-targets and --refresh-targets cannot be used together; use either option once only"
          exit 1
        fi
        __keep_targets=0
        __targetcli="--refresh-targets"
        shift
        ;;
      --non-interactive)
        __non_interactive=1
        shift
        ;;
      --debug)
        __debug=1
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        shift
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi

# __env_migrate used to be called w/ arguments and checks for that
# shellcheck disable=SC2119
  __env_migrate
  if [ "${__migrated}" -eq 1 ] && ! cmp -s "${__env_file}" "${__env_file}".source; then  # Create .bak early
    ${__as_owner} cp "${__env_file}".source "${__env_file}".bak
  fi
  __pull_and_build

  __delete_erigon
  __delete_reth
  __upgrade_postgres

  echo
  if [ "${__migrated}" -eq 1 ] && ! cmp -s "${__env_file}" "${__env_file}".source; then
    ${__as_owner} rm "${__env_file}".source  # .bak was created earlier
    echo "Your ${__env_file} configuration settings have been migrated to a fresh copy. You can \
find the original contents in ${__env_file}.bak."
    if [ "${__keep_targets}" -eq 0 ]; then
      echo "NB: If you made changes to the source or binary build targets, these have been \
reset to defaults."
    fi
    echo
    echo "List of changes made to ${__env_file} during migration - current on left, original on right:"
    echo
    diff -y --suppress-common-lines "${__env_file}" "${__env_file}".bak || true
  else
    echo "No changes made to ${__env_file} during update"
    if [ -f "${__env_file}".source ]; then
      ${__as_owner} rm "${__env_file}".source || true
    fi
  fi
  echo
  if [ -z "${GITEXITCODE+x}" ] || [ "${GITEXITCODE}" -eq 0 ]; then
    if [ "${__enabled_v6}" -eq 0 ]; then  # Remove after Pectra
      echo "An \"$__me up\" command will start using the new images and configuration."
    else
      echo "IPv4/6 dual-stack support has been enabled."
      echo "An \"$__me restart\" command will start using the new images and configuration."
    fi
  else
    echo "WARNING"
    echo
    echo "Updating ${__project_name} failed during \"git pull\""
    echo
    echo "Please try \"git pull\" manually."
    echo "Do not run \"$__me up\" until git can update ${__project_name}."
    echo "The current partial update risks startup failure."
  fi

  __nag_os_version

  unset ETHDSECUNDO
  unset GITEXITCODE
  if [ "${__dirty}" -eq 1 ]; then
    echo
    echo "WARNING"
    echo
    echo "You have uncommitted local changes to ${__project_name}, which may interfere with updates."
    echo "Please undo these changes or \"git commit\" them."
    echo "These are the files with local changes:"
    echo
    ${__as_owner} git status --porcelain
  fi
  if [ -n "${ETHDPINNED:-}" ]; then
    echo "${__project_name} version is pinned to ${ETHDPINNED} in \".env\"."
    echo "Please make sure to run compatible client versions."
  fi

# Release lock and remove lock file
  exec 200<&-
  ${__as_owner} rm -f "/tmp/${__lock_file}"

  if [[ -n "${STY:-}" || -n "${TMUX:-}" ]]; then
    echo
    echo "You are in a screen or tmux session. This is good!"
    echo "\"${__me} update\" may have started it for you to ensure the update finishes."
    echo "When you are done, remember to \"exit\" the session."
    echo
  fi

  __during_update=0
}


resync-execution() {
# Check for EL client
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"

  case "${__value}" in
    *erigon.yml* ) __el_volume='erigon-el-data'; __el_client="erigon";;
    *geth.yml* ) __el_volume='geth-el-data'; __el_client="geth";;
    *reth.yml* ) __el_volume='reth-el-data'; __el_client="reth";;
    *besu.yml* ) __el_volume='besu-el-data'; __el_client="besu";;
    *nethermind.yml* ) __el_volume='nethermind-el-data'; __el_client="nethermind";;
    * ) echo "You do not appear to be running an execution layer client. Nothing to do."; return 0;;
  esac

  if ! __dodocker volume ls -q | grep -qi "$(basename "$(realpath .)")[_-]${__el_volume}"; then
    echo "Did not find Docker volume for ${__el_client}. Nothing to do."
    return 0
  fi

  echo "This will stop ${__el_client} and delete its database to force a resync."
  read -rp "WARNING - resync may take days. Do you wish to continue? (No/yes) " __yn
  case $__yn in
    [Yy][Ee][Ss] ) ;;
    * ) echo "Aborting."; exit 130;;
  esac

  __el_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_${__el_volume}"
  echo "Stopping ${__el_client} container"
  __docompose stop execution && __docompose rm -f execution
  __dodocker volume rm "$(__dodocker volume ls -q -f "name=${__el_volume}")"
  __volume_id=""
  if [[ "${__el_volume}" =~ geth-el-data ]]; then
    __legacy_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_geth-eth1-data"
    __volume_id="$(__dodocker volume ls -q -f "name=${__legacy_volume}")"
  elif [[ "${__el_volume}" =~ besu-el-data ]]; then
    __legacy_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_besu-eth1-data"
    __volume_id="$(__dodocker volume ls -q -f "name=${__legacy_volume}")"
  elif [[ "${__el_volume}" =~ nethermind-el-data ]]; then
    __legacy_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_nm-eth1-data"
    __volume_id="$(__dodocker volume ls -q -f "name=${__legacy_volume}")"
  fi
  if [ -n "${__volume_id}" ]; then
    __dodocker volume rm "${__volume_id}"
  fi
  echo
  echo "${__el_client} stopped and database deleted."
  echo
  echo "Restarting for resync."
  up
}


resync-consensus() {
  # Check for CL client
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"

  case "${__value}" in
    *lighthouse.yml* | *lighthouse-cl-only.yml* ) __cl_volume='lhconsensus-data'; __cl_client="lighthouse";;
    *teku-allin1.yml* ) __cl_volume='wipe-db'; __cl_client="teku";;
    *teku.yml* | *teku-cl-only.yml* ) __cl_volume='tekuconsensus-data'; __cl_client="teku";;
    *nimbus-allin1.yml* ) __cl_volume='wipe-db'; __cl_client="nimbus";;
    *nimbus.yml* | *nimbus-cl-only.yml* ) __cl_volume='nimbus-consensus-data'; __cl_client="nimbus";;
    *lodestar.yml* | *lodestar-cl-only.yml* ) __cl_volume='lsconsensus-data'; __cl_client="lodestar";;
    *prysm.yml* | *prysm-cl-only.yml* ) __cl_volume='prysmconsensus-data'; __cl_client="prysm";;
    *grandine-allin1.yml* ) __cl_volume='wipe-db'; __cl_client="grandine";;
    *grandine.yml* | *grandine-cl-only.yml* ) __cl_volume='grandineconsensus-data'; __cl_client="grandine";;
    *erigon.yml* ) __cl_volume='wipe-db'; __cl_client="caplin";;
    * ) echo "You do not appear to be running a consensus layer client. Nothing to do."; return;;
  esac

  if [ ! "${__cl_volume}" = "wipe-db" ] && ! __dodocker volume ls -q \
      | grep -qi "$(basename "$(realpath .)")[_-]${__cl_volume}"; then
    echo "Did not find Docker volume for ${__cl_client}. Nothing to do."
    return 0
  fi

  # Can we checkpoint sync?
  __var="CHECKPOINT_SYNC_URL"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  echo "This will stop ${__cl_client} and delete its database to force a resync."
  if [ -z "${__value}" ]; then
    read -rp "WARNING - CHECKPOINT_SYNC_URL not set, resync may take days. Do you wish to continue? (No/yes) " __yn
  else
    read -rp "CHECKPOINT_SYNC_URL set, resync should finish in minutes. Do you wish to continue? (No/yes) " __yn
  fi
  case $__yn in
    [Yy][Ee][Ss] ) ;;
    * ) echo "Aborting."; exit 130;;
  esac

  echo "Stopping ${__cl_client} container"
  if [[ "${__cl_client}" = "caplin" ]]; then
    __docompose stop execution && __docompose rm -f execution
  else
    __docompose stop consensus && __docompose rm -f consensus
  fi
  if [ "${__cl_volume}" = "wipe-db" ]; then
    __docompose run --rm wipe-db
  else
    __cl_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_${__cl_volume}"
    __dodocker volume rm "$(__dodocker volume ls -q -f "name=${__cl_volume}")"
    __volume_id=""
    if [[ "${__cl_volume}" =~ lhconsensus-data ]]; then
      __legacy_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_lhbeacon-data"
      __volume_id="$(__dodocker volume ls -q -f "name=${__legacy_volume}")"
    elif [[ "${__cl_volume}" =~ prysmconsensus-data ]]; then
      __legacy_volume="$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_prysmbeacon-data"
      __volume_id="$(__dodocker volume ls -q -f "name=${__legacy_volume}")"
    fi
    if [ -n "${__volume_id}" ]; then
      __dodocker volume rm "${__volume_id}"
    fi
  fi
  echo
  echo "${__cl_client} stopped and database deleted."
  echo
  echo "Restarting for resync."
  up
}


attach-geth() {
  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  if ! grep -q '^COMPOSE_FILE=.*geth\.yml' "${__env_file}" 2>/dev/null ; then
    echo "You do not appear to be using Geth, aborting."
    exit 1
  fi
  __legacy_datadir=$(__dodocker run --rm -v "$(__dodocker volume ls -q -f \
    "name=$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')[_-]geth-eth1-data")":"/var/lib/goethereum" \
    alpine:3 sh -c 'if [ -d "/var/lib/goethereum/geth/chaindata" ]; then echo true; else echo false; fi')

  if [ "${__legacy_datadir}" = "true" ]; then
    __docompose exec -it execution bash -c "geth attach /var/lib/goethereum/geth.ipc"
  else
    __docompose exec -it execution bash -c "geth attach /var/lib/geth/geth.ipc"
  fi
}


prune-besu() {
  __non_interactive=0
  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --non-interactive)
        __non_interactive=1
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        exit 1
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi

  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  if ! grep -q '^COMPOSE_FILE=.*besu\.yml' "${__env_file}" 2>/dev/null ; then
    echo "You do not appear to be using Besu, aborting."
    exit 1
  fi

  # Check for archive node
  __var="ARCHIVE_NODE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  if [[ "${__value}" = "true" ]]; then
    echo "Besu is an archive node: Aborting."
    exit 1
  fi

  __rpc_line=$(grep '^EL_RPC_PORT=' "${__env_file}")
  __regex='^EL_RPC_PORT=([0-9]+)'
  if [[ ! "${__rpc_line}" =~ ${__regex} ]]; then
    echo "Unable to determine EL_RPC_PORT, aborting."
    exit 1
  else
    __rpc_port="${BASH_REMATCH[1]}"
  fi

  set +e
  __sync_status=$(__docompose exec -T execution wget -qO- "http://localhost:$__rpc_port" \
  --header 'Content-Type: application/json' --post-data '{"jsonrpc":"2.0","method":"eth_syncing","params":[],"id":1}')
  __exitstatus=$?
  set -e
  if [ $__exitstatus -ne 0 ]; then
    echo "Unable to connect to Besu: Is it running?"
    echo "Output: ${__sync_status}"
    echo "Aborting."
    exit 1
  fi

  if [[ ! "${__sync_status}" =~ "false" ]]; then
    echo "Besu is not done syncing yet. Sync status:"
    echo "${__sync_status}"
    echo
    echo "Aborting."
    exit 1
  fi

  if [ $__non_interactive = 0 ]; then
    while true; do
      read -rp "WARNING - this will stop Besu and prune its trie-logs. Do you wish to continue? (No/Yes) " __yn
      case $__yn in
        [Yy][Ee][Ss] ) break;;
        * ) echo "Aborting, no changes made"; exit 130;;
      esac
    done
  fi

  echo
  echo "Starting Besu prune"
  echo
  __docompose run --rm set-prune-marker "touch /var/lib/besu/prune-marker"
  __docompose stop execution && __docompose rm -f execution
  start
  echo
  echo "Prune is running, you can observe it with '$__me logs -f execution'"
  echo
  echo "When prune is done, Besu will automatically start again."
  echo
}


prune-reth() {
  __non_interactive=0
  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --non-interactive)
        __non_interactive=1
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        exit 1
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi

  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  if ! grep -q '^COMPOSE_FILE=.*reth\.yml' "${__env_file}" 2>/dev/null ; then
    echo "You do not appear to be using Reth, aborting."
    exit 1
  fi

  # Check for archive node
  __var="ARCHIVE_NODE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  if [[ "${__value}" = "true" ]]; then
    echo "Reth is an archive node: Aborting."
    exit 1
  fi

  __rpc_line=$(grep '^EL_RPC_PORT=' "${__env_file}")
  __regex='^EL_RPC_PORT=([0-9]+)'
  if [[ ! "${__rpc_line}" =~ ${__regex} ]]; then
    echo "Unable to determine EL_RPC_PORT, aborting."
    exit 1
  else
    __rpc_port="${BASH_REMATCH[1]}"
  fi

  set +e
  __sync_status=$(__docompose exec -T execution wget -qO- "http://localhost:$__rpc_port" \
  --header 'Content-Type: application/json' --post-data '{"jsonrpc":"2.0","method":"eth_syncing","params":[],"id":1}')
  __exitstatus=$?
  set -e
  if [ $__exitstatus -ne 0 ]; then
    echo "Unable to connect to Reth: Is it running?"
    echo "Output: ${__sync_status}"
    echo "Aborting."
    exit 1
  fi

  if [[ ! "${__sync_status}" =~ "false" ]]; then
    echo "Reth is not done syncing yet. Sync status:"
    echo "${__sync_status}"
    echo
    echo "Aborting."
    exit 1
  fi

  if [ $__non_interactive = 0 ]; then
    while true; do
      read -rp "WARNING - this will stop Reth and prune its database. Do you wish to continue? (No/Yes) " __yn
      case $__yn in
        [Yy][Ee][Ss] ) break;;
        * ) echo "Aborting, no changes made"; exit 130;;
      esac
    done
  fi

  echo
  echo "Starting Reth prune"
  echo
  __docompose run --rm set-prune-marker "touch /var/lib/reth/prune-marker"
  __docompose stop execution && __docompose rm -f execution
  start
  echo
  echo "Prune is running, you can observe it with '$__me logs -f execution'"
  echo
  echo "When prune is done, Reth will automatically start again."
  echo
}


prune-nethermind() {
  __non_interactive=0
  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --non-interactive)
        __non_interactive=1
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        exit 1
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi

  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  if ! grep -q '^COMPOSE_FILE=.*nethermind\.yml' "${__env_file}" 2>/dev/null ; then
    echo "You do not appear to be using Nethermind, aborting."
    exit 1
  fi

  # Check for archive node
  __var="ARCHIVE_NODE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  if [[ "${__value}" = "true" ]]; then
    echo "Nethermind is an archive node: Aborting."
    exit 1
  fi

  __get_docker_free_space

  __var="NETWORK"
  __get_value_from_env "${__var}" "${__env_file}" "NETWORK"

  if [ "${NETWORK}" = "mainnet" ] || [ "${NETWORK}" = "gnosis" ]; then
    __min_free=262144000
    __min_gib=250
  else
    __min_free=26214400
    __min_gib=25
  fi

  if [ "${__free_space}" -lt ${__min_free} ]; then
    echo "You do not have enough free disk space. Make sure this reads at least ${__min_gib}G free (Avail):"
    echo
    __display_docker_dir
    echo
    echo "Aborting."
    exit 1
  fi

  __rpc_line=$(grep '^EL_RPC_PORT=' "${__env_file}")
  __regex='^EL_RPC_PORT=([0-9]+)'
  if [[ ! "${__rpc_line}" =~ ${__regex} ]]; then
    echo "Unable to determine EL_RPC_PORT, aborting."
    exit 1
  else
    __rpc_port="${BASH_REMATCH[1]}"
  fi

  set +e
  __sync_status=$(__docompose exec -T execution wget -qO- "http://localhost:$__rpc_port" --header \
    'Content-Type: application/json' --post-data '{"jsonrpc":"2.0","method":"eth_syncing","params":[],"id":1}')
  __exitstatus=$?
  set -e
  if [ $__exitstatus -ne 0 ]; then
    echo "Unable to connect to Nethermind: Is it running?"
    echo "Output: ${__sync_status}"
    echo "Aborting."
    exit 1
  fi

  if [[ ! "${__sync_status}" =~ "false" ]]; then
    echo "Nethermind is not done syncing yet. Sync status:"
    echo "${__sync_status}"
    echo
    echo "Aborting."
    exit 1
  fi

  __var="AUTOPRUNE_NM"
  __get_value_from_env "${__var}" "${__env_file}" "__auto_prune"

  if [ $__non_interactive = 0 ]; then
    while true; do
      if [ "${__auto_prune}" = true ]; then
        if [ "${NETWORK}" = "mainnet" ] || [ "${NETWORK}" = "gnosis" ]; then
          __threshold="350"
        else
          __threshold="50"
        fi
        echo "Nethermind should auto-prune below ${__threshold} GiB free. Check logs with \"$__me logs -f --tail 500 \
execution | grep Full\" to see whether it is."
      fi
      read -rp "WARNING - this will prune Nethermind's database in the background. Do you wish to continue? (No/Yes) " __yn
      case $__yn in
        [Yy][Ee][Ss] ) break;;
        * ) echo "Aborting, no changes made"; exit 130;;
      esac
    done
  fi

  echo
  echo "Starting Nethermind prune"
  echo

  set +e
  __prune_result=$(__docompose exec -T execution wget -qO- "http://localhost:1337" --header \
  'Content-Type: application/json' --post-data '{"jsonrpc":"2.0","method":"admin_prune","params":[],"id":1}')
  __exitstatus=$?
  set -e
  if [ $__exitstatus -ne 0 ]; then
    echo "Unable to start prune, error code ${__exitstatus}. This is likely a bug."
    echo "An attempt to run it returned this: ${__prune_result}"
    # shellcheck disable=SC2028
    echo 'The command attempted was: docker compose run --rm set-prune-marker "curl -s \
--data {\\\"method\\\":\\\"admin_prune\\\",\\\"params\\\":[],\\\"id\\\":1,\\\"jsonrpc\\\":\\\"2.0\\\"} \
-H Content-Type:\ application/json http://execution:8545"'
    exit ${__exitstatus}
  fi
  echo "Nethermind returns ${__prune_result}"
  if [[ ! "${__prune_result}" =~ [Ss]tarting ]]; then
    echo "Unable to start prune. This is likely a bug."
    exit 70
  fi
  echo
  echo "Prune is running, you can observe it with \"$__me logs -f --tail 500 execution | grep Full\""
  echo
  echo "Please do not restart the node or restart Nethermind until prune is done."
  echo
  echo "When prune is done, Nethermind will automatically re-start."
  echo
}


prune-lighthouse() {
  __non_interactive=0
  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --non-interactive)
        __non_interactive=1
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        exit 1
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi

  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "lighthouse.yml" && ! "${__value}" =~ "lighthouse-cl-only.yml" ]]; then
    echo "You do not appear to be using Lighthouse, aborting."
    exit 1
  fi

  # Check for archive node
  __var="ARCHIVE_NODE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  if [[ "${__value}" = "true" ]]; then
    echo "Lighthouse is an archive node: Aborting."
    exit 1
  fi

  __rpc_line=$(grep '^CL_REST_PORT=' "${__env_file}")
  __regex='^CL_REST_PORT=([0-9]+)'
  if [[ ! "${__rpc_line}" =~ ${__regex} ]]; then
    echo "Unable to determine CL_REST_PORT, aborting."
    exit 1
  else
    __rpc_port="${BASH_REMATCH[1]}"
  fi

  set +e
  __sync_status=$(__docompose exec -T consensus wget -qO- "http://localhost:$__rpc_port/eth/v1/node/syncing")
  __exitstatus=$?
  set -e
  if [ $__exitstatus -ne 0 ]; then
    echo "Unable to connect to Lighthouse: Is it running?"
    echo "Output: ${__sync_status}"
    echo "Aborting."
    exit 1
  fi

  if [[ "${__sync_status}" =~ "true" ]]; then # Avoid jq - if el_offline or is_optimistic or is_syncing, don't proceed
    echo "Lighthouse is not done syncing yet. Sync status:"
    echo "${__sync_status}"
    echo
    echo "Aborting."
    exit 1
  fi

  if [ $__non_interactive = 0 ]; then
    while true; do
      read -rp "WARNING - this will stop Lighthouse and prune its state. Do you wish to continue? (No/Yes) " __yn
      case $__yn in
        [Yy][Ee][Ss] ) break;;
        * ) echo "Aborting, no changes made"; exit 130;;
      esac
    done
  fi

  echo
  echo "Starting Lighthouse prune"
  echo
  __docompose run --rm set-cl-prune-marker "touch /var/lib/lighthouse/beacon/prune-marker"
  __docompose stop consensus && __docompose rm -f consensus
  start
  echo
  echo "Prune is running, you can observe it with '$__me logs -f consensus'"
  echo
  echo "When prune is done, Lighthouse will automatically start again."
  echo
}


__prep-keyimport() {
  if [ ! -f "${__env_file}" ]; then
    echo "${__env_file} configuration file not found, aborting."
    exit 1
  fi

  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "prysm.yml" ]] && [[ ! "${__value}" =~ "lighthouse.yml" ]] && [[ ! "${__value}" =~ "teku.yml" ]] \
       && [[ ! "${__value}" =~ "nimbus.yml" ]] && [[ ! "${__value}" =~ "lodestar.yml" ]] && \
       [[ ! "${__value}" =~ "-allin1.yml" ]] && [[ ! "${__value}" =~ "vc-only.yml" ]]; then
    echo "You do not appear to be running a validator client. Aborting."
    exit 1
  fi

  __args=""

  while :
  do
    if [ -z "${1+x}" ]; then
      break
    fi
    case "$1" in
      --path)
        if [ -z "${2+x}" ]; then
          echo "--path requires a directory path, aborting"
          exit 1
        fi
        if [ ! -d "$2" ]; then
          echo "$2 is not a directory"
          exit 1
        fi
        if [ "$(realpath "$2")" = "$(realpath ".eth/validator_keys")" ]; then
          echo "$2 is the default path, doing nothing special"
          shift 2
          continue
        fi
        IFS=$'\n'
        __files=$(find "$2" -maxdepth 1 -name '*.json')
        # Unset restores default
        unset IFS
        if [ -z "$__files" ]; then
          echo "No .json files found in $2, aborting"
          exit 1
        fi
        IFS=$'\n'
        __files=$(find ./.eth/validator_keys -maxdepth 1 -name '*.json')
        # Unset restores default
        unset IFS
        if [ -n "$__files" ]; then
          ${__as_owner} mkdir -p ./.eth/validator_keys/keybackup
          ${__as_owner} mv -uf ./.eth/validator_keys/*.json ./.eth/validator_keys/keybackup
          ${__as_owner} rm -f ./.eth/validator_keys/*.json
          echo "Moved existing json files to .eth/validator_keys/keybackup"
        fi
        ${__as_owner} cp "$2"/*.json .eth/validator_keys/
        shift 2
        ;;
      --non-interactive)
        if [ -z "${KEYSTORE_PASSWORD+x}" ]; then
          echo "KEYSTORE_PASSWORD not set or empty, aborting"
          exit 1
        fi
        __args+="${__args:+ }--interactive"
        shift
        ;;
      --debug)
        __args+="${__args:+ }--debug"
        shift
        ;;
      *)
        echo "Error: Unknown option: $1" >&2
        exit 1
        ;;
    esac
  done
  if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
    __non_interactive=1
  fi
}


__i_haz_deposit_cli() {
  if [ ! -f "${__env_file}" ]; then
    echo "${__project_name} has not been configured. Please run $__me config first."
    exit 0
  fi
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "deposit-cli.yml" ]]; then
    echo "Please edit the ${__env_file} file and make sure \":deposit-cli.yml\" is added to the \"COMPOSE_FILE\" line"
    echo "For example, \"nano ${__env_file}\" will open the nano text editor with the \"${__env_file}\" file loaded."
    echo "Without it, this step cannot be run"
    echo
    __var="NETWORK"
    __get_value_from_env "${__var}" "${__env_file}" "__value"
    if [[ "${__value}" = "mainnet" ]]; then
      echo "WARNING: On Ethereum mainnet, best practice is to run key generation on an air-gapped live USB,"
      echo "such as Ubuntu Live or Tails."
      echo
    fi
    exit 1
  fi
}


__i_haz_ethdo() {
  if [ ! -f "${__env_file}" ]; then
    echo "${__project_name} has not been configured. Please run $__me config first."
    exit 0
  fi
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "ethdo.yml" ]]; then
    echo "Please edit the ${__env_file} file and make sure \":ethdo.yml\" is added to the \"COMPOSE_FILE\" line"
    echo "For example, \"nano ${__env_file}\" will open the nano text editor with the \"${__env_file}\" file loaded."
    echo "Without it, this step cannot be run"
    echo
    read -rp "Do you want me to make this change for you? (n/y)" __yn
    case $__yn in
      [Yy] );;
      * ) exit 130;;
    esac
    if [ -n "${__value}" ]; then
      COMPOSE_FILE="${__value}:ethdo.yml"
    else
      COMPOSE_FILE="ethdo.yml"
      echo "You do not have a CL in ${__project_name}. Please make sure CL_NODE in ${__env_file} points at an available one"
    fi
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
    echo "Your COMPOSE_FILE now reads ${COMPOSE_FILE}"
  fi
}


__i_haz_web3signer() {
  if [ ! -f "${__env_file}" ]; then
    echo "${__project_name} has not been configured. Please run $__me config first."
    exit 0
  fi

  __var="WEB3SIGNER"
  __get_value_from_env "${__var}" "${__env_file}" "__w3s"
# shellcheck disable=SC2154
  if [ ! "${__w3s}" = "true" ]; then
    return 0
  fi

  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
  if [[ ! "${__value}" =~ "web3signer.yml" ]]; then
    echo "WEB3SIGNER=true in ${__env_file}, but web3signer.yml is not in use"
    echo "Please edit the ${__env_file} file and make sure \":web3signer.yml\" is added to the \"COMPOSE_FILE\" line"
    echo "For example, \"nano ${__env_file}\" will open the nano text editor with the \"${__env_file}\" file loaded."
    echo "Without it, $__me keys cannot be run"
    echo
    read -rp "Do you want me to make this change for you? (n/y)" __yn
    case $__yn in
      [Yy] );;
      * ) exit 130;;
    esac
    if [ -n "${__value}" ]; then
      COMPOSE_FILE="${__value}:web3signer.yml"
    else
      echo "You do not have a validator client in ${__project_name}. web3signer cannot be used without one."
      exit 1
    fi
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
    echo "Your COMPOSE_FILE now reads ${COMPOSE_FILE}"
  fi
}


__i_haz_keys_service() {
# This caused issues and is currently not being called
  if ! __docompose --profile tools config --services | grep -q validator-keys; then
    if [[ "${1:-}" = "silent" ]]; then
      return 1
    fi
    echo "The validator-keys service is not defined. Are you running only a consensus layer client?"
    echo "Key management happens on the validator client / web3signer, not the consensus layer client."
    echo "You can however do things like send an exit message, prep a withdrawal credentials change,"
    echo "sign exit messages with ethdo."
    echo
    echo "Aborting."
    exit 1
  fi
  return 0
}


__keys_usage() {
  echo "Call keymanager with an ACTION, one of:"
  echo "  create-for-csm"
  echo "      Create keys for Lido CSM"
  echo "  list"
  echo "      Lists the public keys of all validators currently loaded into your validator client"
  echo "  count"
  echo "      Counts the keys currently loaded into your validator client"
  echo "  import"
  echo "      Import all keystore*.json in .eth/validator_keys while loading slashing protection data"
  echo "      in slashing_protection*.json files that match the public key(s) of the imported validator(s)"
  echo "  delete 0xPUBKEY | all"
  echo "      Deletes the validator with public key 0xPUBKEY from the validator client, and exports its"
  echo "      slashing protection database."
  echo "      \"all\" deletes all detected validators."
  echo "  register"
  echo "      For use with web3signer only: Re-register all keys in web3signer with the validator client"
  echo
  echo "  get-recipient 0xPUBKEY"
  echo "      List fee recipient set for the validator with public key 0xPUBKEY"
  echo "      Validators will use FEE_RECIPIENT in ${__env_file} by default, if not set individually"
  echo "  set-recipient 0xPUBKEY 0xADDRESS"
  echo "      Set individual fee recipient for the validator with public key 0xPUBKEY"
  echo "  delete-recipient 0xPUBKEY"
  echo "      Delete individual fee recipient for the validator with public key 0xPUBKEY"
  echo
  echo "  get-gas 0xPUBKEY"
  echo "      List execution gas limit set for the validator with public key 0xPUBKEY"
  echo "      Validators will use the client's default, if not set individually"
  echo "  set-gas 0xPUBKEY amount"
  echo "      Set individual execution gas limit for the validator with public key 0xPUBKEY"
  echo "  delete-gas 0xPUBKEY"
  echo "      Delete individual execution gas limit for the validator with public key 0xPUBKEY"
  echo
  echo "  get-graffiti 0xPUBKEY"
  echo "      List graffiti set for the validator with public key 0xPUBKEY"
  echo "      Validators will use GRAFFITI in .env by default, if not set individually"
  echo "  set-graffiti 0xPUBKEY amount"
  echo "      Set individual graffiti for the validator with public key 0xPUBKEY"
  echo "  delete-graffiti 0xPUBKEY"
  echo "      Delete individual graffiti for the validator with public key 0xPUBKEY"
  echo
  echo "  get-api-token"
  echo "      Print the token for the keymanager API running on port ${KEY_API_PORT:-7500}."
  echo "      This is also the token for the Prysm Web UI"
  echo
  echo "  create-prysm-wallet"
  echo "      Create a new Prysm wallet to store keys in"
  echo "  get-prysm-wallet"
  echo "      Print Prysm's wallet password"
  echo
  echo "  get-grandine-wallet"
  echo "      Print Grandine's wallet password"
  echo
  echo "  prepare-address-change"
  echo "      Create an offline-preparation.json with ethdo"
  echo "  send-address-change"
  echo "      Send a change-operations.json with ethdo, setting the withdrawal address"
  echo
  echo "  sign-exit 0xPUBKEY | all"
  echo "      Create pre-signed exit message for the validator with public key 0xPUBKEY"
  echo "      \"all\" signs an exit message for all detected validators"
  echo "  sign-exit from-keystore [--offline]"
  echo "      Create pre-signed exit messages with ethdo, from keystore files in ./.eth/validator_keys"
  echo "  send-exit"
  echo "      Send pre-signed exit messages in ./.eth/exit_messages to the Ethereum chain"
  echo
  echo " Commands can be appended with \"--debug\" to see debug output"
}


__get_github_release() {
# Call with repo and expected suffix as well as directory and target name.

  local __repo=$1
  local __suffix=$2
  local __dirname=$3
  local __targetname=$4

  ${__as_owner} mkdir -p "${__dirname}"
  if [ "${__targetname}" = "__untar__" ]; then
    wget -q -O- https://api.github.com/repos/"${__repo}"/releases/latest | grep "browser_download_url.*${__suffix}" \
      | head -1 \
      | cut -d : -f 2,3 \
      | tr -d \" \
      | wget -qi- -O- \
      | ${__as_owner} tar zxf - -C "${__dirname}" \
      || echo "-> Could not download the latest version of '${__suffix}' from github '${__repo}'."
  else
    wget -q -O- https://api.github.com/repos/"${__repo}"/releases/latest | grep "browser_download_url.*${__suffix}" \
      | head -1 \
      | cut -d : -f 2,3 \
      | tr -d \" \
      | ${__as_owner} wget -qi- -O "${__dirname}/${__targetname}" \
      && ${__as_owner} chmod +x "${__dirname}/${__targetname}" \
      || echo "-> Could not download the latest version of '${__suffix}' from github '${__repo}'."
  fi
}


keys() {
  if [[ "$#" -eq 0 || "$1" = "help" || "$1" = "-h" || "$1" = "--help" ]]; then
    __keys_usage
    return 0
  fi

  __i_haz_web3signer

  __owner_uid=$(id -u "${OWNER}")
  if [ "${1:-}" = "import" ]; then
    #__i_haz_keys_service
    shift
    __prep-keyimport "$@"
    __docompose run --rm -e OWNER_UID="${__owner_uid}" validator-keys import "${__args}"
  elif [ "${1:-}" = "create-prysm-wallet" ]; then
    __var="COMPOSE_FILE"
    __get_value_from_env "${__var}" "${__env_file}" "__value"
# Literal match intended
# shellcheck disable=SC2076
    if [[ ! "${__value}" =~ "prysm.yml" ]] && [[ ! "${__value}" =~ "prysm-vc-only.yml" ]]; then
      echo "You do not appear to be using a Prysm validator. Aborting."
      exit 1
    fi
    if __docompose run --rm create-wallet; then
      __docompose stop validator
      __docompose rm --force validator
      up
    fi
  elif [ "${1:-}" = "create-for-csm" ]; then
    __i_haz_deposit_cli
    __var="NETWORK"
    __get_value_from_env "${__var}" "${__env_file}" "NETWORK"
    __query_lido_keys_generation
  elif [ "${1:-}" = "prepare-address-change" ]; then
    __i_haz_ethdo
    echo "Generating offline prep file"
    set +e
    __docompose run --rm ethdo validator credentials set --prepare-offline
    __exitstatus=$?
    set -e
    if [ "${__exitstatus}" -ne 0 ]; then
      echo "Running ethdo failed, unfortunately. Is the CL running and synced?"
      echo "Please try again after fixing root cause. Aborting."
      exit 1
    fi
    echo
    echo "Downloading ethdo"
    __get_github_release wealdtech/ethdo linux-amd64.tar.gz ./.eth/ethdo/amd64 __untar__
    __get_github_release wealdtech/ethdo linux-arm64.tar.gz ./.eth/ethdo/arm64 __untar__
    echo
    echo "Downloading jq"
    __get_github_release jqlang/jq jq-linux-amd64 ./.eth/ethdo/amd64 jq
    __get_github_release jqlang/jq jq-linux-arm64 ./.eth/ethdo/arm64 jq
    echo
    echo "Copy the contents of ./.eth/ethdo to a USB drive, and prepare a Linux Live USB to safely enter your mnemonic."
    echo "Please see https://ethdocker.com/Support/ChangingWithdrawalCredentials for details"
  elif [ "${1:-}" = "send-address-change" ]; then
    __i_haz_ethdo
    __docompose run --rm ethdo validator credentials set
  elif [ "${1:-}" = "sign-exit" ] && [ "${2:-}" = "from-keystore" ]; then
    __i_haz_ethdo

    if echo "$@" | grep -q '.*--offline.*' 2>/dev/null ; then
      __offline="--offline"
    else
      __offline=""
    fi

    __non_interactive=0
    if echo "$@" | grep -q '.*--non-interactive.*' 2>/dev/null ; then
      __non_interactive=1
    fi
    if [ "${ETHD_FRONTEND:-}" = "noninteractive" ]; then
      __non_interactive=1
    fi

    if [ ${__non_interactive} = 1 ]; then
      __password="${KEYSTORE_PASSWORD}"
      __justone=1
    else
      __num_files=$(find .eth/validator_keys -maxdepth 1 -type f -name 'keystore*.json' | wc -l)
      if [ "$__num_files" -eq 0 ]; then
        echo "No keystore*.json files found in .eth/validator_keys/"
        echo "Nothing to do"
        exit 0
      fi

      if [ "$__num_files" -gt 1 ]; then
        while true; do
          read -rp "Do all validator keys have the same password? (y/n) " __yn
          case $__yn in
            [Yy]* ) __justone=1; break;;
            [Nn]* ) __justone=0; break;;
            * ) echo "Please answer yes or no.";;
          esac
        done
      else
        __justone=1
      fi
      if [ "${__justone}" -eq 1 ]; then
        while true; do
          read -srp "Please enter the password for your validator key(s): " __password
          echo
          read -srp "Please re-enter the password: " __password2
          echo
          if [ "${__password}" = "${__password2}" ]; then
            break
          else
            echo "The two entered passwords do not match, please try again."
            echo
          fi
        done
        echo
      fi
    fi

    __created=0
    __failed=0
    for __keyfile in .eth/validator_keys/keystore-*.json; do
      [ -f "${__keyfile}" ] || continue # Should always evaluate true - just in case
      if [ "${__justone}" -eq 0 ]; then
        while true; do
          read -srp "Please enter the password for your validator key stored in ${__keyfile}: " __password
          echo
          read -srp "Please re-enter the password: " __password2
          echo
          if [ "${__password}" = "${__password2}" ]; then
            break
          else
            echo "The two entered passwords do not match, please try again."
            echo
          fi
          echo
        done
      fi

      __pubkey="$(sed -E 's/.*"pubkey":\s*"([0-9a-fA-F]+)".*/\1/' < "${__keyfile}")"
      if [ -z "$__pubkey" ]; then
        echo "Unable to read public key from ${__keyfile}. Is it the right format?"
        continue
      else
          __pubkey="0x${__pubkey}"
      fi
      set +e
      # __offline may be empty, don't quote it
      # shellcheck disable=SC2086
      __json=$(__docompose run --rm ethdo validator exit --validator "${__keyfile}" --json --timeout 2m \
        --passphrase "${__password}" ${__offline})
      __exitstatus=$?
      if [ "${__exitstatus}" -eq 0 ]; then
        echo "${__json}" >".eth/exit_messages/${__pubkey::10}--${__pubkey:90}-exit.json"
# shellcheck disable=SC2320
        __exitstatus=$?
        if [ "${__exitstatus}" -eq 0 ]; then
          echo "Creating an exit message for validator ${__pubkey} into file \
./.eth/exit_messages/${__pubkey::10}--${__pubkey:90}-exit.json succeeded"
          (( __created++ ))
        else
          echo "Error writing exit json to file ./.eth/exit_messages/${__pubkey::10}--${__pubkey:90}-exit.json"
          (( __failed++ ))
        fi
      else
        echo "Creating an exit message for validator ${__pubkey} from file ${__keyfile} failed"
        (( __failed++ ))
      fi
      set -e
    done
    echo
    echo "Created pre-signed exit messages for ${__created} validators"
    if [ "${__created}" -gt 0 ]; then
      echo "You can find them in ./.eth/exit_messages"
    fi
    if [ "${__failed}" -gt 0 ]; then
      echo "Failed for ${__failed} validators"
    fi
  #elif [ "${1:-}" = "send-exit" ] && ! __i_haz_keys_service silent; then
  elif [ "${1:-}" = "send-exit" ]; then
    __var="CL_NODE"
    __get_value_from_env "${__var}" "${__env_file}" "CL_NODE"
    CL_NODE="${CL_NODE%%,*}"
    __network_name="$(__docompose config | awk '
      BEGIN {
          found_networks=0;
          found_default=0;
      }
      /networks:/ {
          found_networks=1;
          next;
      }
      found_networks && /default:/ {
          found_default=1;
          next;
      }
      found_default && /^ *name:/ {
          print $2;
          exit;
      }
      ')"
    if ! __dodocker image ls --format "{{.Repository}}:{{.Tag}}" | grep -q "vc-utils:local"; then
      if ! dpkg-query -W -f='${Status}' docker-ce 2>/dev/null | grep -q "ok installed"; then
        __dodocker build -t vc-utils:local ./vc-utils
      else
        if ! dpkg-query -W -f='${Status}' docker-buildx-plugin 2>/dev/null | grep -q "ok installed"; then
          ${__auto_sudo} apt-get update && ${__auto_sudo} apt-get install -y docker-buildx-plugin
        fi
        __dodocker buildx build -t vc-utils:local ./vc-utils
      fi
    fi
    __dodocker run --rm \
      -u 1000:1000 \
      --network "${__network_name}" \
      --name send-exit \
      -v "$(pwd)/.eth/exit_messages:/exit_messages" \
      -v "/etc/localtime:/etc/localtime:ro" \
      -e "CL_NODE=${CL_NODE}" \
      --entrypoint "keymanager.sh" \
      vc-utils:local /var/lib/lighthouse/nonesuch.txt eth2 send-exit
  else
    #__i_haz_keys_service
    __docompose run --rm -e OWNER_UID="${__owner_uid}" validator-keys "$@"
  fi
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
}


upgrade() {
  update
}


start() {
  __docompose up -d --remove-orphans "$@"
}

# Passed by user
# shellcheck disable=SC2120
up() {
  start "$@"
}


run() {
  start "$@"
}


stop() {
  __docompose down --remove-orphans "$@"
}


down() {
  stop "$@"
}


restart() {
  stop "$@"
  start "$@"
}


logs() {
  __docompose logs "$@"
}


cmd() {
  __docompose "$@"
}


terminate() {
  if [ -z "$(__dodocker volume ls -q -f "name=^$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_[^_]+")" ]; then
    echo "There are no data stores - Docker volumes - left to remove for this Ethereum node."
    stop
    return 0
  fi

  while true; do
    read -rp "WARNING - this action will destroy all data stores for this Ethereum node. Do you wish to continue? \
(No/Yes) " __yn
    case $__yn in
      [Yy][Ee][Ss] ) break;;
      * ) echo "Aborting, no changes made"; exit 130;;
    esac
  done

  stop
# In this case I want the word splitting, so rm can remove all volumes
# shellcheck disable=SC2046
  __dodocker volume rm $(__dodocker volume ls -q -f "name=^$(basename "$(realpath .)" | tr '[:upper:]' '[:lower:]')_[^_]+")
  echo
  echo "All containers stopped and all volumes deleted"
  echo
}


__query_network() {
  __var="NETWORK"
  __get_value_from_env "${__var}" "${__env_file}" "__prev_network"
  NETWORK=$(whiptail --notags --title "Select Network" --menu \
  "Which network do you want to run on?" 14 65 6 \
  "hoodi" "Hoodi Testnet" \
  "ephemery" "Ephemery Testnet" \
  "mainnet" "Ethereum Mainnet" \
  "gnosis" "Gnosis Chain" \
  "sepolia" "Sepolia Testnet (permissioned validators)" \
  "custom" "Custom Testnet (needs a URL)" 3>&1 1>&2 2>&3)

  case "${NETWORK}" in
    "mainnet")
      echo "You chose to run on Ethereum mainnet"
      ;;
    "gnosis")
      echo "You chose to run on Gnosis Chain"
      ;;
    "sepolia" | "hoodi" )
      echo "You chose to run on ${NETWORK} testnet"
      ;;
    "custom" )
      while true; do
        NETWORK=$(whiptail --title "Configure testnet URL" --inputbox "What is github URL of your custom testnet \
spec? (right-click to paste)" 10 60 3>&1 1>&2 2>&3)
        if [[ ${NETWORK} =~ ^https?:// ]]; then
          echo "Your custom testnet URL is: ${NETWORK}"
          break
        else
          whiptail --msgbox "${NETWORK} is not a valid URL. You can try again or Cancel on the next \
screen.\n\nCustom testnets only work with a URL to fetch their configuration from." 12 65
        fi
      done
      ;;
  esac
# shellcheck disable=SC2154
  if [ ! "${NETWORK}" = "${__prev_network}" ]; then
    __network_change=1
  else
    __network_change=0
  fi
}


__query_deployment() {
  if [ "${NETWORK}" = "gnosis" ]; then
    if uname -m | grep -q riscv64; then
      echo "Gnosis network has no available client combos on RISC-V. Aborting."
      exit 1
    fi
    __deployment=$(whiptail --notags --title "Select deployment type" --menu \
    "What kind of deployment do you want to run?" 11 65 3 \
    "node" "Ethereum node - consensus, execution and validator client" \
    "rpc" "Ethereum RPC node - consensus and execution client" \
    "validator" "Validator client only" 3>&1 1>&2 2>&3)
  elif [ "${NETWORK}" = "ephemery" ]; then
    if uname -m | grep -q riscv64; then
      echo "Ephemery network has no available client combos on RISC-V. Aborting."
      exit 1
    fi
    __deployment=$(whiptail --notags --title "Select deployment type" --menu \
    "What kind of deployment do you want to run?" 11 65 3 \
    "node" "Ethereum node - consensus, execution and validator client" \
    "rpc" "Ethereum RPC node - consensus and execution client" \
    "validator" "Validator client only" 3>&1 1>&2 2>&3)
  elif uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
    __deployment=$(whiptail --notags --title "Select deployment type" --menu \
    "What kind of deployment do you want to run?" 12 65 4 \
    "node" "Ethereum node - consensus, execution and validator client" \
    "rpc" "Ethereum RPC node - consensus and execution client" \
    "lido_comp" "Lido-compatible node (Community Staking / Simple DVT)" \
    "rocket" "Validator client only - integrate with RocketPool" 3>&1 1>&2 2>&3)
  elif uname -m | grep -q riscv64; then
    __deployment=$(whiptail --notags --title "Select deployment type" --menu \
    "What kind of deployment do you want to run?" 11 65 3 \
    "node" "Ethereum node - consensus, execution and validator client" \
    "rpc" "Ethereum RPC node - consensus and execution client" \
    "rocket" "Validator client only - integrate with RocketPool" 3>&1 1>&2 2>&3)
  elif uname -m | grep -q x86_64; then
    __deployment=$(whiptail --notags --title "Select deployment type" --menu \
    "What kind of deployment do you want to run?" 13 65 5 \
    "node" "Ethereum node - consensus, execution and validator client" \
    "rpc" "Ethereum RPC node - consensus and execution client" \
    "lido_comp" "Lido-compatible node (Community Staking / Simple DVT)" \
    "rocket" "Validator client only - integrate with RocketPool" \
    "ssv" "SSV node - consensus, execution and ssv-node" 3>&1 1>&2 2>&3)
  else
    echo "Eth Docker does not recognize this CPU architecture. Aborting."
    echo "Output of uname -m"
    uname -m
    exit 1
  fi

  if [ "${__deployment}" = "lido_comp" ]; then
    if uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
      __deployment=$(whiptail --notags --title "Select deployment type for Lido" --menu \
      "What kind of deployment to participate in Lido protocol do you want to run?" 11 90 3 \
      "lido_csm" "[Community Staking] CSM node - Consensus, execution and validator client" \
      "lido_obol" "[Simple DVT] Obol node - Nodes, validator client and charon node (obol middleware)" 3>&1 1>&2 2>&3)
    elif uname -m | grep -q x86_64; then
      __deployment=$(whiptail --notags --title "Select deployment type for Lido" --menu \
      "What kind of deployment to participate in Lido protocol do you want to run?" 11 90 3 \
      "lido_csm" "[Community Staking] CSM node - Consensus, execution and validator client" \
      "lido_ssv" "[Simple DVT] SSV node - Consensus, execution and ssv-node" \
      "lido_obol" "[Simple DVT] Obol node - Nodes, validator client and charon node (obol middleware)" 3>&1 1>&2 2>&3)
    else
      echo "Eth Docker does not support Lido on this CPU architecture. Aborting."
      echo "Output of uname -m"
      uname -m
      exit 1
    fi
  fi

  echo "Your deployment choice is: ${__deployment}"
}


__query_validator_client() {
  if [ "${NETWORK}" = "gnosis" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
    "Which validator client do you want to run?" 12 65 4 \
    "lighthouse-vc-only.yml" "Lighthouse validator client" \
    "teku-vc-only.yml" "Teku validator client" \
    "lodestar-vc-only.yml" "Lodestar validator client" \
    "nimbus-vc-only.yml" "Nimbus validator client" 3>&1 1>&2 2>&3)
  elif [ "${NETWORK}" = "ephemery" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
    "Which validator client do you want to run?" 9 65 2 \
    "teku-vc-only.yml" "Teku validator client" \
    "lodestar-vc-only.yml" "Lodestar validator client" \
    3>&1 1>&2 2>&3)
  elif [ "${__deployment}" = "rocket" ]; then
    if uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
      CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
      "Which validator client do you want to run?" 12 65 4 \
      "lighthouse-vc-only.yml" "Lighthouse validator client" \
      "teku-vc-only.yml" "Teku validator client" \
      "lodestar-vc-only.yml" "Lodestar validator client" \
      "nimbus-vc-only.yml" "Nimbus validator client" 3>&1 1>&2 2>&3)
    else
      CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
      "Which validator client do you want to run?" 12 65 4 \
      "teku-vc-only.yml" "Teku validator client" \
      "lighthouse-vc-only.yml" "Lighthouse validator client" \
      "lodestar-vc-only.yml" "Lodestar validator client" \
      "nimbus-vc-only.yml" "Nimbus validator client" 3>&1 1>&2 2>&3)
    fi
  elif uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
    "Which validator client do you want to run?" 13 65 5 \
    "lighthouse-vc-only.yml" "Lighthouse validator client" \
    "teku-vc-only.yml" "Teku validator client" \
    "lodestar-vc-only.yml" "Lodestar validator client" \
    "nimbus-vc-only.yml" "Nimbus validator client" \
    "prysm-vc-only.yml" "Prysm validator client" 3>&1 1>&2 2>&3)
  else
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select validator client" --menu \
    "Which validator client do you want to run?" 13 65 5 \
    "teku-vc-only.yml" "Teku validator client" \
    "lighthouse-vc-only.yml" "Lighthouse validator client" \
    "lodestar-vc-only.yml" "Lodestar validator client" \
    "nimbus-vc-only.yml" "Nimbus validator client" \
    "prysm-vc-only.yml" "Prysm validator client" 3>&1 1>&2 2>&3)
  fi

  echo "Your validator client file is:" "${CONSENSUS_CLIENT}"
}


__query_consensus_client() {
  if [ "${NETWORK}" = "gnosis" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 13 65 5 \
    "teku.yml" "Teku (Java) - consensus and validator client" \
    "lighthouse.yml" "Lighthouse (Rust) - consensus and validator client" \
    "lodestar.yml" "Lodestar (TypeScript) - consensus and validator client" \
    "nimbus.yml" "Nimbus (Nim) - consensus and validator client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
    3>&1 1>&2 2>&3)
  elif [ "${NETWORK}" = "ephemery" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 9 65 2 \
    "teku.yml" "Teku (Java) - consensus and validator client" \
    "lodestar.yml" "Lodestar (TypeScript) - consensus and validator client" \
    3>&1 1>&2 2>&3)
  elif uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 15 65 7 \
    "nimbus.yml" "Nimbus (Nim) - consensus and validator client" \
    "grandine-allin1.yml" "Grandine (Rust) - consensus with built-in validator client" \
    "lodestar.yml" "Lodestar (TypeScript) - consensus and validator client" \
    "teku.yml" "Teku (Java) - consensus and validator client" \
    "lighthouse.yml" "Lighthouse (Rust) - consensus and validator client" \
    "prysm.yml" "Prysm (Go) - consensus and validator client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
     3>&1 1>&2 2>&3)
  elif uname -m | grep -q riscv64; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 9 65 1 \
    "nimbus.yml" "Nimbus (Nim) - consensus and validator client" 3>&1 1>&2 2>&3)
  else
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 15 65 7 \
    "teku.yml" "Teku (Java) - consensus and validator client" \
    "grandine-allin1.yml" "Grandine (Rust) - consensus with built-in validator client" \
    "lodestar.yml" "Lodestar (TypeScript) - consensus and validator client" \
    "nimbus.yml" "Nimbus (Nim) - consensus and validator client" \
    "lighthouse.yml" "Lighthouse (Rust) - consensus and validator client" \
    "prysm.yml" "Prysm (Go) - consensus and validator client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
    3>&1 1>&2 2>&3)
  fi

  if [[ "${__deployment}" = "lido_obol" && "${CONSENSUS_CLIENT}" = "lodestar.yml" ]]; then
    CONSENSUS_CLIENT="lodestar-cl-only.yml:lodestar-vc-only.yml"  # Charon does not handle SSZ
  fi

  echo "Your consensus client file is:" "${CONSENSUS_CLIENT}"
}


__query_consensus_only_client() {
  if [ "${NETWORK}" = "gnosis" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 13 65 5 \
    "lighthouse-cl-only.yml" "Lighthouse (Rust) - consensus client" \
    "teku-cl-only.yml" "Teku (Java) - consensus client" \
    "lodestar-cl-only.yml" "Lodestar (TypeScript) - consensus client" \
    "nimbus-cl-only.yml" "Nimbus (Nim) - consensus client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
    3>&1 1>&2 2>&3)
  elif [ "${NETWORK}" = "ephemery" ]; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 9 65 2 \
    "teku-cl-only.yml" "Teku (Java) - consensus client" \
    "lodestar-cl-only.yml" "Lodestar (TypeScript) - consensus client" \
    3>&1 1>&2 2>&3)
  elif uname -m | grep -q aarch64 || uname -m | grep -q arm64; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 13 65 7 \
    "nimbus-cl-only.yml" "Nimbus (Nim) - consensus client" \
    "grandine-cl-only.yml" "Grandine (Rust) - consensus client" \
    "lodestar-cl-only.yml" "Lodestar (TypeScript) - consensus client" \
    "lighthouse-cl-only.yml" "Lighthouse (Rust) - consensus client" \
    "teku-cl-only.yml" "Teku (Java) - consensus client" \
    "prysm-cl-only.yml" "Prysm (Go) - consensus client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
    3>&1 1>&2 2>&3)
  elif uname -m | grep -q riscv64; then
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 9 65 1 \
    "nimbus-cl-only.yml" "Nimbus (Nim) - consensus client" 3>&1 1>&2 2>&3)
  else
    CONSENSUS_CLIENT=$(whiptail --notags --title "Select consensus client" --menu \
    "Which consensus client do you want to run?" 14 65 7 \
    "teku-cl-only.yml" "Teku (Java) - consensus client" \
    "grandine-cl-only.yml" "Grandine (Rust) - consensus client" \
    "lighthouse-cl-only.yml" "Lighthouse (Rust) - consensus client" \
    "nimbus-cl-only.yml" "Nimbus (Nim) - consensus client" \
    "lodestar-cl-only.yml" "Lodestar (TypeScript) - consensus client" \
    "prysm-cl-only.yml" "Prysm (Go) - consensus client" \
    "caplin" "Caplin (Go) - Erigon's built-in CL" \
    3>&1 1>&2 2>&3)
  fi

  echo "Your consensus client file is:" "${CONSENSUS_CLIENT}"
}


__query_custom_execution_client() {
  if [ "${__minty_fresh}" -eq 1 ]; then
    EL_CUSTOM_NODE=""
    JWT_SECRET=""
  else
    __var="EL_NODE"
    __get_value_from_env "${__var}" "${__env_file}" "EL_CUSTOM_NODE"
    __var="JWT_SECRET"
    __get_value_from_env "${__var}" "${__env_file}" "JWT_SECRET"
  fi
  EL_CUSTOM_NODE=$(whiptail --title "Configure custom execution client" --inputbox "What is the URL for your custom \
execution client? (right-click to paste)" 10 65 "${EL_CUSTOM_NODE}" 3>&1 1>&2 2>&3)

  echo "Your custom execution client is: $EL_CUSTOM_NODE"

  while true; do
    JWT_SECRET=$(whiptail --title "Configure JWT secret" --inputbox "What is the JWT secret shared with the \
execution client? (right-click to paste)" 10 60 "${JWT_SECRET}" 3>&1 1>&2 2>&3)

    # Remove '0x' prefix if present
    JWT_SECRET=${JWT_SECRET#0x}

    # Check if the JWT_SECRET is exactly 64 hex characters long
    if [[ $JWT_SECRET =~ ^[0-9A-Fa-f]{64}$ ]]; then
      echo "JWT Secret set. Please make sure it matches on CL and EL."
      break
    else
      whiptail --msgbox "The JWT secret needs to be exactly 32 bytes, 64 hex characters long. You can try \
again or Cancel on the next screen." 10 65
    fi
  done
}


__query_execution_client() {
  if [ "${CONSENSUS_CLIENT}" = "caplin" ]; then
    EXECUTION_CLIENT="erigon.yml"
    echo "Your execution client file is:" "${EXECUTION_CLIENT}"
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
    EL_NODE="http://execution:8551"
    echo "Please remember to set your EL_WS_PORT to match EL_RPC_PORT for Erigon"
    return 0
  fi

  __choices=()
  __arch=$(uname -m)

  if [ "${NETWORK}" = "gnosis" ]; then
    __choices+=("nethermind.yml" "Nethermind (.NET)")
    __choices+=("erigon.yml" "Erigon (Go)")
  elif [[ "${NETWORK}" = "ephemery" ]]; then
    if [[ "${__arch}" != *"riscv64"* ]]; then
      __choices+=("besu.yml" "Besu (Java)")
    else
      echo "Epheremy testnet is not supported on ${__arch}"
      exit 1
    fi
  elif [[ "${__arch}" =~ (aarch64|arm64) ]] ; then
    __choices+=("besu.yml" "Besu (Java)")
    __choices+=("nethermind.yml" "Nethermind (.NET)")
    __choices+=("erigon.yml" "Erigon (Go)")
    __choices+=("geth.yml" "Geth (Go)")
  elif [[ "${__arch}" = *"riscv64"* ]]; then
    __choices+=("geth.yml" "Geth (Go)")
  else
    __choices+=("reth.yml" "Reth (Rust)")
    __choices+=("besu.yml" "Besu (Java)")
    __choices+=("nethermind.yml" "Nethermind (.NET)")
    __choices+=("erigon.yml" "Erigon (Go)")
    __choices+=("geth.yml" "Geth (Go)")
  fi

  if [[ "${__arch}" != *"riscv64"* ]] && [[ "${NETWORK}" =~ (hoodi|sepolia) ]]; then
    __choices+=("nimbus-el.yml" "Nimbus (Nim) - alpha")
  fi

  __choices+=("NONE" "Custom - Distributed")
  __num_items=$(( ${#__choices[@]} / 2 ))
  __menu_height=$(( 8 + __num_items ))

  EXECUTION_CLIENT=$(whiptail --notags --title "Select execution client" --menu \
  "Which execution client do you want to run?" "${__menu_height}" 65 "${__num_items}" \
  "${__choices[@]}" 3>&1 1>&2 2>&3)

  if [ "${EXECUTION_CLIENT}" = "NONE" ]; then
    unset EXECUTION_CLIENT
    __query_custom_execution_client
    EL_NODE="${EL_CUSTOM_NODE}"
  else
    echo "Your execution client file is:" "${EXECUTION_CLIENT}"
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
    EL_NODE="http://execution:8551"
    if [ "${EXECUTION_CLIENT}" = "erigon.yml" ]; then
        echo "Please remember to set your EL_WS_PORT to match EL_RPC_PORT for Erigon"
    fi
  fi
}


__query_4444() {  # Call with with --defaultno for RPC
  if (whiptail --title "History expiry" --yesno "Do you want to expire pre-merge history? Good for a validator node, but makes eth_getLogs RPC calls impossible pre-merge" 10 65 "$1") then
    EL_MINIMAL_NODE=true
  else
# shellcheck disable=SC2034
    EL_MINIMAL_NODE=false
  fi
}


__query_grafana() {
  if (whiptail --title "Grafana" --yesno "Do you want to use Grafana dashboards?" 10 65) then
      if [[ "$OSTYPE" = "darwin"* ]]; then
      # macOS doesn't do well with / bind mount - leave node-exporter, cadvisor and loki/promtail off by default
        GRAFANA_CLIENT="grafana-rootless.yml:grafana-shared.yml"
      else
        GRAFANA_CLIENT="grafana.yml:grafana-shared.yml"
      fi
  else
    unset GRAFANA_CLIENT
  fi
}


__query_remote_beacon() {
  if [ "${__minty_fresh}" -eq 1 ]; then
    if [ "${__deployment}" = "rocket" ]; then
      REMOTE_BEACON="http://eth2:5052"
    else
      REMOTE_BEACON=""
    fi
  else
    __var="CL_NODE"
    __get_value_from_env "${__var}" "${__env_file}" "REMOTE_BEACON"
  fi
  REMOTE_BEACON=$(whiptail --title "Configure remote consensus client" --inputbox "What is the URL for your remote \
consensus client? (right-click to paste)" 10 60 "${REMOTE_BEACON}" 3>&1 1>&2 2>&3)

  echo "Your remote consensus client is:" "${REMOTE_BEACON}"
}


__query_checkpoint_beacon() {
  if [ "${__minty_fresh}" -eq 1 ] || [ "${__network_change}" -eq 1 ]; then
    CHECKPOINT_SYNC_URL=""
  else
    __var="CHECKPOINT_SYNC_URL"
    __get_value_from_env "${__var}" "${__env_file}" "CHECKPOINT_SYNC_URL"
  fi
  if [ -z "${CHECKPOINT_SYNC_URL}" ]; then
    case "${NETWORK}" in
      "sepolia")
        CHECKPOINT_SYNC_URL="https://sepolia.beaconstate.info"
        ;;
      "hoodi")
        CHECKPOINT_SYNC_URL="https://hoodi.beaconstate.info"
        ;;
      "ephemery")
        CHECKPOINT_SYNC_URL="https://ephemery.beaconstate.ethstaker.cc/"
        ;;
      "mainnet")
        CHECKPOINT_SYNC_URL="https://beaconstate.info"
        ;;
      "gnosis")
        CHECKPOINT_SYNC_URL="https://checkpoint.gnosischain.com"
        ;;
      *)
        CHECKPOINT_SYNC_URL=""
        ;;
    esac
  fi

  CHECKPOINT_SYNC_URL=$(whiptail --title "Configure CL checkpoint sync URL" --inputbox "What is the URL for your CL \
checkpoint sync provider? (right-click to paste)" 10 65 "${CHECKPOINT_SYNC_URL}" 3>&1 1>&2 2>&3)

  echo "Your checkpoint sync URL is:" "${CHECKPOINT_SYNC_URL}"
}


__query_graffiti() {
  __var="GRAFFITI"
  __get_value_from_env "${__var}" "${__env_file}" "GRAFFITI"
  __var="DEFAULT_GRAFFITI"
  __get_value_from_env "${__var}" "${__env_file}" "DEFAULT_GRAFFITI"

  while true; do
    GRAFFITI=$(whiptail --title "Configure Graffiti" --inputbox "What optional Graffiti do you want to send with your blocks? \
(up to 32 characters)" 10 65 "${GRAFFITI}" 3>&1 1>&2 2>&3)

    if [[ $(echo -n "${GRAFFITI}" | wc -c) -gt 32 ]]; then
      whiptail --msgbox "The graffiti string cannot be longer than 32 characters. Emojis count as 4, each." 16 65
    else
      break
    fi
  done

  if [ -n "${GRAFFITI}" ]; then
    DEFAULT_GRAFFITI="false"
  fi
  if [ "${DEFAULT_GRAFFITI}" = "true" ]; then
    echo "You are using the client's default Graffiti"
  else
    echo "your Graffiti is:" "${GRAFFITI}"
  fi
}


__query_checkpoint_sync() {
  if [[ "${NETWORK}" =~ ^https?:// ]]; then
    CHECKPOINT_SYNC_URL=""
    return
  fi
  __query_checkpoint_beacon
}


__query_coinbase() {
  __var="FEE_RECIPIENT"
  __get_value_from_env "${__var}" "${__env_file}" "FEE_RECIPIENT"

  while true; do
    set +e # Can't rely on the error handler here because of the special-casing below for update()
    if [[  "${__during_update}" -eq 0 && "${__deployment}" =~ "lido_" ]]; then  # Lido Execution Layer Rewards Vault
      case "${NETWORK}" in
        "mainnet")
          FEE_RECIPIENT="0x388C818CA8B9251b393131C08a736A67ccB19297"
          ;;
        "hoodi")
          FEE_RECIPIENT="0x9b108015fe433F173696Af3Aa0CF7CDb3E104258"
          ;;
        *)
          FEE_RECIPIENT="0x0000000000000000000000000000000000000000"
          ;;
      esac
    elif [ "${__during_update}" -eq 1 ] || [ ! "${__deployment}" = rpc ]; then
      FEE_RECIPIENT=$(whiptail --title "Configure rewards address" --inputbox "What is the address you want \
transaction rewards to be sent to by default? (right-click to paste, CANNOT be an ENS)" 10 65 "${FEE_RECIPIENT}" \
3>&1 1>&2 2>&3)
    else
      FEE_RECIPIENT=$(whiptail --title "Configure fallback fee recipient" --inputbox "What is the fallback fee recipient \
address? Required so that a) the CL doesn't print warnings and b) you can use the CL REST API for validators. \
(right-click to paste, CANNOT be an ENS)" 10 65 \
"${FEE_RECIPIENT}" 3>&1 1>&2 2>&3)
    fi

    __exitstatus=$?
    set -e
    if [ $__exitstatus -eq 0 ]; then
      if [[ ${FEE_RECIPIENT} = 0x* && ${#FEE_RECIPIENT} -eq 42 ]]; then
        echo "Your rewards address is: ${FEE_RECIPIENT}"
        break
      else
        whiptail --msgbox "${FEE_RECIPIENT} is not a valid ETH address. You can try again or Cancel on the next \
screen.\n\nThe client will not start successfully until a valid ETH rewards address has been set." 16 65
      fi
    else
      if [ $__during_update -eq 1 ]; then
        echo
        echo "Please make requested changes manually or run \"$__me update\" again"
        echo "before running \"$__me up\"."
        echo
        echo "Without a FEE_RECIPIENT set in \"${__env_file}\", containers will not"
        echo "start successfully. Already running containers will keep running with the"
        echo "old configuration until you are ready to restart them."
      else
        echo "Canceled config wizard."
      fi
      echo
      exit 130
    fi
  done
}


__query_mev() {
  if [ "${NETWORK}" = "gnosis" ]; then
    return 0
  fi
  if [ "${__deployment}" = "ssv" ]; then
    MEV_BOOST="true"
    case "${NETWORK}" in
      "hoodi")
        MEV_RELAYS="https://0xaa58208899c6105603b74396734a6263cc7d947f444f396a90f7b7d3e65d102aec7e5e5291b27e08d02c50a050825c2f@hoodi.titanrelay.xyz,https://0x98f0ef62f00780cf8eb06701a7d22725b9437d4768bb19b363e882ae87129945ec206ec2dc16933f31d983f8225772b6@hoodi.aestus.live,https://0xafa4c6985aa049fb79dd37010438cfebeb0f2bd42b115b89dd678dab0670c1de38da0c4e9138c9290a398ecd9a0b3110@boost-relay-hoodi.flashbots.net,https://0xb1559beef7b5ba3127485bbbb090362d9f497ba64e177ee2c8e7db74746306efad687f2cf8574e38d70067d40ef136dc@relay-hoodi.ultrasound.money"
        ;;
      "mainnet")
        MEV_RELAYS="https://0xac6e77dfe25ecd6110b8e780608cce0dab71fdd5ebea22a16c0205200f2f8e2e3ad3b71d3499c54ad14d6c21b41a37ae@boost-relay.flashbots.net,\
https://0x8b5d2e73e2a3a55c6c87b8b6eb92e0149a125c852751db1422fa951e42a09b82c142c3ea98d0d9930b056a3bc9896b8f@bloxroute.max-profit.blxrbdn.com,\
https://0xa1559ace749633b997cb3fdacffb890aeebdb0f5a3b6aaa7eeeaf1a38af0a8fe88b9e4b1f61f236d2e64d95733327a62@relay.ultrasound.money,\
https://0xa15b52576bcbf1072f4a011c0f99f9fb6c66f3e1ff321f11f461d15e31b1cb359caa092c71bbded0bae5b5ea401aab7e@aestus.live,\
https://0x98650451ba02064f7b000f5768cf0cf4d4e492317d82871bdc87ef841a0743f69f0f1eea11168503240ac35d101c9135@mainnet-relay.securerpc.com"
        ;;
    esac
    return 0
  fi
  __var="MEV_BOOST"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  # I do mean to match literally
  # shellcheck disable=SC2076
  if [[ "${CONSENSUS_CLIENT}" =~ "-vc-only.yml" && ! "${__deployment}" =~ "lido_obol" ]]; then
    if (whiptail --title "MEV Boost" --yesno "Is MEV Boost configured on your remote consensus client and do you \
want to use MEV Boost?" 10 65); then
        MEV_BOOST="true"
        MEV_RELAYS=""
      fi
      return 0
  fi
  if [[ "${__deployment}" =~ "lido_" ]]; then
    MEV_BOOST="true"
    while true; do
      MEV_RELAYS=""
      __selected=""
      declare -A relays=()
      declare -A optional_relays=()
      case "${NETWORK}" in
          "mainnet")
              relays=(
                  ['Agnostic']="https://0xa7ab7a996c8584251c8f925da3170bdfd6ebc75d50f5ddc4050a6fdc77f2a3b5fce2cc750d0865e05d7228af97d69561@agnostic-relay.net"
                  ['bloXroute']="https://0xb0b07cd0abef743db4260b0ed50619cf6ad4d82064cb4fbec9d3ec530f7c5e6793d9f286c4e082c0244ffb9f2658fe88@bloxroute.regulated.blxrbdn.com"
                  ['Aestus']="https://0xa15b52576bcbf1072f4a011c0f99f9fb6c66f3e1ff321f11f461d15e31b1cb359caa092c71bbded0bae5b5ea401aab7e@aestus.live"
                  ['bloXroute Max-Profit']="https://0x8b5d2e73e2a3a55c6c87b8b6eb92e0149a125c852751db1422fa951e42a09b82c142c3ea98d0d9930b056a3bc9896b8f@bloxroute.max-profit.blxrbdn.com"
                  ['Flashbots']="https://0xac6e77dfe25ecd6110b8e780608cce0dab71fdd5ebea22a16c0205200f2f8e2e3ad3b71d3499c54ad14d6c21b41a37ae@boost-relay.flashbots.net"
                  ['Ultra Sound']="https://0xa1559ace749633b997cb3fdacffb890aeebdb0f5a3b6aaa7eeeaf1a38af0a8fe88b9e4b1f61f236d2e64d95733327a62@relay.ultrasound.money"
              )
              optional_relays=(
                  ['Titan Relay Global']="https://0x8c4ed5e24fe5c6ae21018437bde147693f68cda427cd1122cf20819c30eda7ed74f72dece09bb313f2a1855595ab677d@global.titanrelay.xyz"
                  ['Titan Relay Regional']='https://0x8c4ed5e24fe5c6ae21018437bde147693f68cda427cd1122cf20819c30eda7ed74f72dece09bb313f2a1855595ab677d@regional.titanrelay.xyz'
                  ['Manifold Finance']="https://0x98650451ba02064f7b000f5768cf0cf4d4e492317d82871bdc87ef841a0743f69f0f1eea11168503240ac35d101c9135@mainnet-relay.securerpc.com/"
              )
              __selected=$(whiptail --title "Relays list" --checklist \
                  "Choose relays (use spacebar to unselect)" 16 50 9 \
                  "Agnostic" "" ON \
                  "bloXroute" "" ON \
                  "Aestus" "" ON \
                  "bloXroute Max-Profit" "" ON \
                  "Flashbots" "" ON \
                  "Ultra Sound" "" ON \
                  "Titan Relay Global" "(optional)" ON \
                  "Titan Relay Regional" "(optional)" ON \
                  "Manifold Finance" "(optional)" ON 3>&1 1>&2 2>&3)
              ;;
          "hoodi")
              relays=(
                  ['Aestus']="https://0x98f0ef62f00780cf8eb06701a7d22725b9437d4768bb19b363e882ae87129945ec206ec2dc16933f31d983f8225772b6@hoodi.aestus.live"
                  ['Titan']="https://0xaa58208899c6105603b74396734a6263cc7d947f444f396a90f7b7d3e65d102aec7e5e5291b27e08d02c50a050825c2f@hoodi.titanrelay.xyz"
                  ['Flashbots']="https://0xafa4c6985aa049fb79dd37010438cfebeb0f2bd42b115b89dd678dab0670c1de38da0c4e9138c9290a398ecd9a0b3110@boost-relay-hoodi.flashbots.net"
                  ['Ultrasound']="https://0xb1559beef7b5ba3127485bbbb090362d9f497ba64e177ee2c8e7db74746306efad687f2cf8574e38d70067d40ef136dc@relay-hoodi.ultrasound.money"
              )
              __selected=$(whiptail --title "Relays list" --checklist \
                  "Choose relays" 12 30 5 \
                  "Aestus" "" ON \
                  "Titan" "" ON \
                  "Flashbots" "" ON \
                  "Ultrasound" "" ON \
                  3>&1 1>&2 2>&3)
              ;;
            *)
              echo "No MEV RELAYS configured for ${NETWORK}"
              return
              ;;
      esac
      for i in "${!relays[@]}"; do
          if [[ ${__selected} =~ ${i} ]]; then
              if [ -z "${MEV_RELAYS}" ]; then
                  MEV_RELAYS="${relays[$i]}"
              else
                  MEV_RELAYS="${MEV_RELAYS},${relays[$i]}"
              fi
          fi
      done
      exitstatus=$?
      if [ $exitstatus -eq 0 ]; then
          if [ -z "${MEV_RELAYS}" ]; then
            whiptail --msgbox "At least one mandatory relay should be chosen" 10 75
            continue
          fi
      else
          echo "You chose Cancel."
          exit 1
      fi
      for i in "${!optional_relays[@]}"; do
          if [[ ${__selected} =~ ${i} ]]; then
              if [ -z "${MEV_RELAYS}" ]; then
                  MEV_RELAYS="${optional_relays[$i]}"
              else
                  MEV_RELAYS="${MEV_RELAYS},${optional_relays[$i]}"
              fi
          fi
      done
      break
    done
    return 0
  fi
  if [ "${__deployment}" = "rpc" ]; then
    __message="Do you want to use MEV Boost, e.g. because you will connect validators to CL REST API?"
    __default="--defaultno"
  else
    __message="Do you want to use MEV Boost?"
    __default=""
  fi
  if (whiptail --title "MEV Boost" --yesno "${__message}" 10 65 "${__default}") then
    MEV_BOOST="true"
    if [ "${__value}" = "true" ]; then
      __var="MEV_RELAYS"
      __get_value_from_env "${__var}" "${__env_file}" "MEV_RELAYS"
    else
      case "${NETWORK}" in
        "sepolia")
          MEV_RELAYS=https://0x845bd072b7cd566f02faeb0a4033ce9399e42839ced64e8b2adcfc859ed1e8e1a5a293336a49feac6d9a5edb779be53a@boost-relay-sepolia.flashbots.net
          ;;
        "hoodi")
          MEV_RELAYS="https://https://0xaa58208899c6105603b74396734a6263cc7d947f444f396a90f7b7d3e65d102aec7e5e5291b27e08d02c50a050825c2f@hoodi.titanrelay.xyz,https://0x98f0ef62f00780cf8eb06701a7d22725b9437d4768bb19b363e882ae87129945ec206ec2dc16933f31d983f8225772b6@hoodi.aestus.live,https://0xafa4c6985aa049fb79dd37010438cfebeb0f2bd42b115b89dd678dab0670c1de38da0c4e9138c9290a398ecd9a0b3110@boost-relay-hoodi.flashbots.net,https://0xb1559beef7b5ba3127485bbbb090362d9f497ba64e177ee2c8e7db74746306efad687f2cf8574e38d70067d40ef136dc@relay-hoodi.ultrasound.money"
          ;;
        "mainnet")
          MEV_RELAYS=https://0xac6e77dfe25ecd6110b8e780608cce0dab71fdd5ebea22a16c0205200f2f8e2e3ad3b71d3499c54ad14d6c21b41a37ae@boost-relay.flashbots.net,\
https://0x8b5d2e73e2a3a55c6c87b8b6eb92e0149a125c852751db1422fa951e42a09b82c142c3ea98d0d9930b056a3bc9896b8f@bloxroute.max-profit.blxrbdn.com,\
https://0x8c4ed5e24fe5c6ae21018437bde147693f68cda427cd1122cf20819c30eda7ed74f72dece09bb313f2a1855595ab677d@global.titanrelay.xyz,\
https://0xa1559ace749633b997cb3fdacffb890aeebdb0f5a3b6aaa7eeeaf1a38af0a8fe88b9e4b1f61f236d2e64d95733327a62@relay.ultrasound.money,\
https://0xa15b52576bcbf1072f4a011c0f99f9fb6c66f3e1ff321f11f461d15e31b1cb359caa092c71bbded0bae5b5ea401aab7e@aestus.live,\
https://0xa7ab7a996c8584251c8f925da3170bdfd6ebc75d50f5ddc4050a6fdc77f2a3b5fce2cc750d0865e05d7228af97d69561@agnostic-relay.net,\
https://0x98650451ba02064f7b000f5768cf0cf4d4e492317d82871bdc87ef841a0743f69f0f1eea11168503240ac35d101c9135@mainnet-relay.securerpc.com,\
https://0x8c7d33605ecef85403f8b7289c8058f440cbb6bf72b055dfe2f3e2c6695b6a1ea5a9cd0eb3a7982927a463feb4c3dae2@relay.wenmerge.com
          ;;
        *)
          MEV_RELAYS=""
          ;;
      esac
    fi
    # Replace newlines with "\n" for the whiptail input
    __formatted_mev_relays=$(printf '%s' "${MEV_RELAYS}" | sed ':a;N;$!ba;s/\n/\\n/g')

    __formatted_mev_relays=$(whiptail --title "Configure MEV relays" --inputbox "What MEV relay(s) do you want to use? \
(right-click to paste)" 15 65 "${__formatted_mev_relays}" 3>&1 1>&2 2>&3)

    # Replace "\n" back to newlines to restore multi-line format
    MEV_RELAYS=$(printf '%s' "${__formatted_mev_relays}" | sed 's/\\n/\n/g')
    echo "Your MEV relay(s): ${MEV_RELAYS}"
  else
    MEV_BOOST="false"
    MEV_RELAYS=""
  fi
}

__lido_withdrawal_credentials_address() {
    __lido_address=""
    case "${NETWORK}" in  # Lido Withdrawal Vault
        "mainnet")
            __lido_address="0xB9D7934878B5FB9610B3fE8A5e441e8fad7E293f"
            ;;
        "hoodi")
            __lido_address="0x4473dCDDbf77679A643BdB654dbd86D67F8d32f2"
            ;;
        *)
            __lido_address="0x0000000000000000000000000000000000000000"
            ;;
    esac
    echo "${__lido_address}"
}

__lido_keys_attention_message() {
  whiptail --title "Attention" --msgbox "Please, make sure that you set 32 ETH when generated deposit data\nAnd right execution address for your validator keys: $(__lido_withdrawal_credentials_address)\nOtherwise, your keys will not be valid!" 10 80
}

__query_lido_keys_generation() {
    if [ "${NETWORK}" = "mainnet" ]; then
      if (whiptail --title "Security warning" --yesno "Key generation is not recommended on MAINNET for security reasons.\n\nIt is recommended to Select 'No' to skip the step and generate keys in a more secure way later (ex. on an airgapped live USB)\n\nOtherwise, Select 'Yes' to proceed with key generation on this machine" 13 85) then
         echo "Proceeding with key generation on MAINNET."
      else
         __lido_keys_attention_message
         return 0
      fi
    fi

    __num_validators="1"
    __keystore_password=""
    __keystore_password_confirm=""
    __num_validators=$(whiptail --title "Validators count" --inputbox "Enter the number of validators" 8 60 "${__num_validators}" 3>&1 1>&2 2>&3)
    while true; do
        __keystore_password=$(whiptail --title "Keystore password" --passwordbox "Enter validators keystore password (at least 8 chars)" 8 60 "${__keystore_password}" 3>&1 1>&2 2>&3)

        exitstatus=$?
        if [ $exitstatus -eq 0 ]; then
            if [[ ${#__keystore_password} -ge 8 ]]; then
              __keystore_password_confirm=$(whiptail --title "Keystore password" --passwordbox "Confirm validators keystore password" 8 60 "${__keystore_password_confirm}" 3>&1 1>&2 2>&3)
              if [ "${__keystore_password}" = "${__keystore_password_confirm}" ]; then
                  echo "Keystore password set."
                  break
              else
                  whiptail --msgbox "Passwords do not match. Please try again." 10 60
              fi
            else
              whiptail --msgbox "The keystore password secret needs to be at least 8 characters long. You can try \
again or Cancel on the next screen." 10 75
            fi
        else
            echo "You chose Cancel."
            exit 1
        fi
    done

    exitstatus=$?
    if [ $exitstatus -eq 0 ]; then
        echo "Your number of validators is:" "${__num_validators}"
        __mnemonic="existing"
        if (whiptail --title "Mnemonic" --yesno "Do you want to generate new mnemonic?" 8 60) then
            __mnemonic="new"
        fi
        export NETWORK=${NETWORK} && __docompose --profile tools run --rm deposit-cli-${__mnemonic} \
            --uid "$(id -u)" \
            --execution_address "$(__lido_withdrawal_credentials_address)" \
            --num_validators "${__num_validators}" \
            --keystore_password "${__keystore_password}" \
            --non_interactive
    else
        echo "You chose Cancel."
        exit 1
    fi
}


__query_lido_obol_enr() {
    ${__as_owner} mkdir -p ./.eth/charon
    __outcome__=$(__docompose -f ./lido-obol.yml run -u "$(id -u)":"$(id -g)" --rm charon-create-enr)
    if [[ "${__outcome__}" =~ "Created ENR private key:" ]]; then
      __lido_obol_operator_enr=$(echo "${__outcome__}" | grep -e 'enr:')
    else
      echo "Something went wrong. Please, try again."
      exit 1
    fi

    echo "Your created ENR is:" "${__lido_obol_operator_enr}"
    echo "${__lido_obol_operator_enr}" >> "./.eth/charon-enr-public-key"
    whiptail --title "Lido Obol operator ENR creation outcome" --msgbox "Your ENR is created!\n\n1. Backup your private key (path: .eth/charon-enr-private-key)!\n2. Copy your public ENR for the further steps\n\nYour public ENR is:\n\n${__lido_obol_operator_enr}" 16 80
}

__query_lido_obol_cluster_definition() {
    __cluster_definition_url=$(whiptail --title "Lido Obol cluster creation" --inputbox "\nPut your cluster definition link below:" 10 80 "https://api.obol.tech/dv/example_link_to_your_definition" 3>&1 1>&2 2>&3)
    if [ "${__cluster_definition_url}" = ""  ]; then
      echo "Cluster definition URL can't be empty"
      exit 1
    fi
    exitstatus=$?
    if [ $exitstatus -eq 0 ]; then
        ${__as_owner} curl -o ./.eth/cluster-definition.tmp -s "${__cluster_definition_url}" -H "Accept: application/json"
# shellcheck disable=SC2086
        __cluster_definition_is_valid=$(__docompose -f ./lido-obol.yml run --rm -v "$(pwd)"/.eth/cluster-definition.tmp:/cluster-definition.json:ro curl-jq sh -c \
          "cat /cluster-definition.json | jq -r 'all(.validators[]; (.fee_recipient_address | ascii_downcase) == (\"'${FEE_RECIPIENT}'\" | ascii_downcase) and (.withdrawal_address | ascii_downcase) == (\"'$(__lido_withdrawal_credentials_address)'\" | ascii_downcase))'" | tail -n 1)
        set -e
        if [ "${__cluster_definition_is_valid}" = "true" ]; then
            echo "Your cluster definition url is:" "${__cluster_definition_url}"
            ${__as_owner} mv ./.eth/cluster-definition.tmp ./.eth/cluster-definition.json
        else
            whiptail --title "Lido Obol cluster creation" --msgbox "Your cluster definition is not valid.\n\nCheck that every validator has \`fee_recipient_address\` and \`withdrawal_address\` equal to Lido contracts and try again.\n\nLido fee recipient: '${FEE_RECIPIENT}'\nLido withdrawal credentials: '$(__lido_withdrawal_credentials_address)'" 14 90
            echo "Your cluster definition is NOT valid."
            ${__as_owner} rm ./.eth/cluster-definition.tmp
            exit 1
        fi
    else
        echo "You chose Cancel."
        exit 1
    fi
}

__query_lido_obol_cluster_dkg() {
    if [ -d ./.eth/validator_keys ]; then
        __folder_postfix=${EPOCHSECONDS}
        ${__as_owner} mkdir ./.eth_backup_"$__folder_postfix"
        ${__as_owner} cp -vr ./.eth/validator_keys ./.eth_backup_"$__folder_postfix"/validator_keys
        ${__as_owner} rm -rf ./.eth/validator_keys
    fi
    if (whiptail --title "DKG ceremony" --yesno "Do you want to start DKG ceremony?\n\nMake sure all participants are ready!" 10 60) then
        __outcome__=$(__docompose -f ./lido-obol.yml run -u "$(id -u)":"$(id -g)" --rm charon-run-dkg)
        exitstatus=$?
        if [ $exitstatus -ne 0 ]; then
            echo "Something went wrong. Please, try again."
            exit 1
        fi
        echo "DKG ceremony finished successfully"
        whiptail --title "Finish" --msgbox "\nThe DKG is finished!" 10 40
    else
        whiptail --title "DKG ceremony" --msgbox "You should start DKG ceremony before proceeding further" 8 60
        echo "DKG ceremony starting is canceled"
        exit 1
    fi
}

__query_dkg() {
  __ssv_operator_id=-1
  if (whiptail --title "DKG ceremony" --yesno "Do you want to participate in DKG ceremonies as an operator?" 10 60); then
    __key_file_content=$(${__auto_sudo} cat ./ssv-config/encrypted_private_key.json)
    __public_key=$(__docompose -f ./ssv-dkg.yml run --rm curl-jq sh -c \
      "echo '${__key_file_content}' | jq -r '.pubKey'" | tail -n 1)
    echo "Your SSV node public key is: ${__public_key}"
    __ssv_operator_id=$(whiptail --title "Register SSV operator" --inputbox "\n1. Your SSV node public key:\n\n${__public_key}\n\n2. Register your operator in the SSV network with the public key\n\n3. Input your Operator ID \
(right-click to paste)" 22 85 3>&1 1>&2 2>&3)
    if [[ -n "${__ssv_operator_id}" && ! "${__ssv_operator_id}" = "-1" ]]; then
      sed -i'.original' "s|operatorID: .*|operatorID: ${__ssv_operator_id}|" ./ssv-config/dkg-config.yaml
      echo "Your SSV Operator ID is: ${__ssv_operator_id}"
    else
      echo "Please manually edit \"./ssv-config/dkg-config.yaml\" with your SSV Operator ID"
      echo "and add \":ssv-dkg.yml\" to \"COMPOSE_FILE\" in \".env\" after registering your operator."
    fi
  fi
  rm -f ssv-config/dkg-config.yaml.original
}


__handle_error() {
  if [[ ! $- =~ e ]]; then
# set +e, do nothing
    return 0
  fi

  local __exit_code=$1
  if [ "$__exit_code" -eq 0 ]; then
    return 0
  fi

  if [[ -n "${__handler_ran:-}" ]]; then
    return 0
  fi
  __handler_ran=1

  echo
  if [ "$__exit_code" -eq 130 ]; then
    echo "$__me terminated by user"
  elif [ "$__during_config" -eq 1 ] && [ "$__exit_code" -eq 1 ]; then
    echo "Canceled config wizard."
  else
    echo "$__me terminated with exit code $__exit_code on line $2"
    if [ -n "${__command}" ]; then
      echo "This happened during $__me ${__command} ${__params}"
    fi
  fi
  if [ "$__during_update" -eq 1 ] && [ "$__during_migrate" -eq 1 ]; then
    cp "${__env_file}" "${__env_file}".partial
    cp "${__env_file}".source "${__env_file}"
    echo
    echo "Restored your ${__env_file} file, to undo partial migration. Please verify it looks correct."
    echo "The partially migrated file is in ${__env_file}.partial for troubleshooting."
  fi
  if [ "$__during_postgres" -eq 1 ]; then
    echo
    if [ "$__during_migrate" -eq 1 ] && [ "$__migrated" -eq 0 ]; then
      echo "Web3signer slashing protection database migration failed, while switching to the migrated data."
      echo
      echo "WARNING: You are no longer protected by the slashing protection database."
      echo "Starting the node again could get you slashed."
      echo
      echo "Marking Web3signer as unsafe to start."
      __dodocker run --rm -v "$(__dodocker volume ls -q -f "name=web3signer-keys")":/var/lib/web3signer \
        alpine:3 touch /var/lib/web3signer/.migration_fatal_error
    elif [ "$__migrated" -eq 1 ]; then
      echo "Web3signer slashing protection database migration failed, after switching to the migrated data."
      echo
      echo "The slashing protection database itself is likely fine, but somewhere in the switch to PostgreSQL 16"
      echo "an error occurred, which is likely to keep your node from functioning correctly."
    else
      echo "Web3signer slashing protection database migration failed, but before removing the original data."
      echo
      echo "Your original Web3signer slashing protection database remains in place."
      echo "You can safely update the node again, this time without migration, and start it."
    fi
  fi
}


__check_legacy() {
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"

# Literal match intended
# shellcheck disable=SC2076
  if [[ "${__value}" =~ "-allin1.yml" && ! "${__value}" =~ "grandine-allin1.yml" ]]; then # Warn re Grandine once VC
    if [[ "${__value}" =~ "teku-allin1.yml" ]]; then
      __client="Teku"
    elif [[ "${__value}" =~ "nimbus-allin1.yml" ]]; then
      __client="Nimbus"
    elif [[ "${__value}" =~ "grandine-allin1.yml" ]]; then
      __client="Grandine"
    else
      __client="Mystery"
    fi
    if ! (whiptail --title "All-In-One detected" --yesno "All-In-One client ${__client} detected. Re-configuration requires re-import of the keys, which has to be treated like a move with 15 minutes downtime, to avoid slashing. Do you wish to continue, regardless?" 10 65 --defaultno) then
      echo "Aborting config"
      exit 0
    fi
  fi
}

config() {
  # Do not track changes to ext-network.yml now. This is removed post-Pectra
  ${__as_owner} git update-index --assume-unchanged ext-network.yml
  # Create ENV file if needed
  if ! [[ -f "${__env_file}" ]]; then
    ${__as_owner} cp default.env "${__env_file}"
    __minty_fresh=1
  else
    __minty_fresh=0
  fi

  __during_config=1

  __check_legacy
  __query_network
  __query_deployment
  case "${__deployment}" in
    "node" | "lido_csm")
      __query_consensus_client
      ;;
    "lido_obol")
      __query_consensus_client
      ;;
    "validator" | "rocket")
      __query_validator_client
      ;;
    "ssv" | "lido_ssv")
      if [ "${NETWORK}" = "hoodi" ]; then
        sed -i'.original' 's/  Network: .*/  Network: hoodi/' ssv-config/config.yaml
      elif [ "${NETWORK}" = "mainnet" ]; then
        sed -i'.original' 's/  Network: .*/  Network: mainnet/' ssv-config/config.yaml
      else
        echo "${NETWORK} is not something that works with SSV."
        echo "Please choose Hoodi or Mainnet when running $__me config again"
        echo "Aborting."
        exit 1
      fi
      rm ssv-config/config.yaml.original
      if [ ! -f "./ssv-config/password.pass" ]; then
        echo "Creating password file for encrypted SSV secret key"
        head -c 16 /dev/urandom | base64 | tr -d '[:space:]' >./ssv-config/password.pass
        ${__auto_sudo} chown 12000:12000 ./ssv-config/password.pass
        ${__auto_sudo} chmod 600 ./ssv-config/password.pass
      fi
      if [ ! -f "./ssv-config/encrypted_private_key.json" ]; then
        echo "Creating encrypted operator private key"
        __dodocker run --name ssv-node-key-generation -v "$(pwd)/ssv-config/password.pass":/password.pass \
          -it ssvlabs/ssv-node:latest /go/bin/ssvnode generate-operator-keys \
          --password-file=/password.pass && __dodocker cp ssv-node-key-generation:/encrypted_private_key.json \
          ./ssv-config/encrypted_private_key.json && __dodocker rm ssv-node-key-generation
        ${__auto_sudo} chown 12000:12000 ./ssv-config/encrypted_private_key.json
      fi
      __query_dkg
      __query_consensus_only_client
      ;;
    "rpc")
      __query_consensus_only_client
      ;;
    *)
      echo "Unknown deployment ${__deployment}, this is a bug."
      exit 70
      ;;
  esac

  MEV_BOOST=false
# I do mean to match literally
# shellcheck disable=SC2076
  if [[ ! "${__deployment}" =~ ^(validator|rocket)$  ]]; then
    if [ "${CONSENSUS_CLIENT}" = "caplin" ]; then
      CL_NODE=http://execution:5052
      __query_execution_client
      if [[ ! "${__deployment}" =~ ^(ssv|lido_ssv|rpc)$  ]]; then
        __query_validator_client  # This sets CONSENSUS_CLIENT
      fi
    else
      CL_NODE="http://consensus:5052"
      __query_execution_client
    fi

    if [[ "${EXECUTION_CLIENT}" =~ (erigon.yml|nimbus-el.yml) ]] \
        && [[ "${NETWORK}" =~ (mainnet|sepolia) ]]; then
      if [[ "${__deployment}" = "rpc" ]]; then
        __query_4444 --defaultno
      else
        __query_4444 ""
      fi
    fi
    __query_checkpoint_sync
    __query_mev
    __query_grafana
    __query_coinbase
    if [[ "${__deployment}" = "node" || "${__deployment}" = "lido_csm" ]]; then
      __query_graffiti
    fi
    if [ "${__deployment}" = "lido_csm" ]; then
      if (whiptail --title "Keys generation" --yesno "Do you want to generate validator keys?" 10 60) then
        __query_lido_keys_generation
      else
        __lido_keys_attention_message
      fi
      if [ "${NETWORK}" = "hoodi" ]; then
        __link="https://csm.testnet.fi/?ref=ethdocker"
      else
        __link="https://csm.lido.fi/?ref=ethdocker"
      fi
      whiptail --title "Finish" --msgbox "Final steps!\n\n1. Run your node './ethd start'\n\n2. Wait until your node is fully synchronized\n\n4. Open ${__link} to submit your keys with '.eth/validator_keys/deposit-data-*.json' file content\n\n5. Wait for keys validation\n\n6. Import your keys by './ethd keys import'" 19 85
    fi
  else
    unset EXECUTION_CLIENT
    unset GRAFANA_CLIENT

    __query_remote_beacon
# This gets used, but shellcheck doesn't recognize that
# shellcheck disable=SC2034
    CL_NODE="${REMOTE_BEACON}"
    __query_mev
    __query_coinbase
    __query_graffiti
  fi

  __during_config=0

  if [ "${__deployment}" = "lido_obol" ]; then
    CL_NODE="http://charon:3600"
    case "${NETWORK}" in  # Lido Locator, and oracle allowlist for exits
      "mainnet")
# We are using the variable
# shellcheck disable=SC2034
        VE_LOCATOR_ADDRESS="0xC1d0b3DE6792Bf6b4b37EccdcC24e45978Cfd2Eb"
# We are using the variable
# shellcheck disable=SC2034
        VE_ORACLE_ADDRESSES_ALLOWLIST='["0x140Bd8FbDc884f48dA7cb1c09bE8A2fAdfea776E","0xA7410857ABbf75043d61ea54e07D57A6EB6EF186","0x404335BcE530400a5814375E7Ec1FB55fAff3eA2","0x946D3b081ed19173dC83Cd974fC69e1e760B7d78","0x007DE4a5F7bc37E2F26c0cb2E8A95006EE9B89b5","0xe57B3792aDCc5da47EF4fF588883F0ee0c9835C9","0x61c91ECd902EB56e314bB2D5c5C07785444Ea1c8","0x73181107c8D9ED4ce0bbeF7A0b4ccf3320C41d12","0xc79F702202E3A6B0B6310B537E786B9ACAA19BAf"]'
# We are using the variable
# shellcheck disable=SC2034
        VE_STAKING_MODULE_ID="2"
# We are using the variable
# shellcheck disable=SC2034
        LIDO_DV_EXIT_EXIT_EPOCH="194048" # capella
        ;;
      "hoodi")
# We are using the variable
# shellcheck disable=SC2034
        VE_LOCATOR_ADDRESS="0xe2EF9536DAAAEBFf5b1c130957AB3E80056b06D8"
# We are using the variable
# shellcheck disable=SC2034
        VE_ORACLE_ADDRESSES_ALLOWLIST='["0xcA80ee7313A315879f326105134F938676Cfd7a9","0xf03B8DC8762B97F13Ac82e6F94bE3Ed002FF7459","0x1932f53B1457a5987791a40Ba91f71c5Efd5788F","0xf7aE520e99ed3C41180B5E12681d31Aa7302E4e5","0x99B2B75F490fFC9A29E4E1f5987BE8e30E690aDF","0x219743f1911d84B32599BdC2Df21fC8Dba6F81a2","0xD3b1e36A372Ca250eefF61f90E833Ca070559970","0x4c75FA734a39f3a21C57e583c1c29942F021C6B7","0xB1cC91878c1831893D39C2Bb0988404ca5Fa7918","0xfe43A8B0b481Ae9fB1862d31826532047d2d538c","0x43C45C2455C49eed320F463fF4f1Ece3D2BF5aE2"]'
# We are using the variable
# shellcheck disable=SC2034
        VE_STAKING_MODULE_ID="2"
# We are using the variable
# shellcheck disable=SC2034
        LIDO_DV_EXIT_EXIT_EPOCH="256" # capella
        ;;
      *)
        ;;
    esac

    if [ -f "./.eth/cluster-lock.json" ]; then
      if (whiptail --title "Lido Obol cluster exists" --yesno "Your cluster has already been created. Continue with it?" 10 60); then
# shellcheck disable=SC2086
        __cluster_lock_is_valid=$(__docompose -f ./lido-obol.yml run --rm -v "$(pwd)"/.eth/cluster-lock.json:/cluster-lock.json:ro curl-jq sh -c \
          "cat /cluster-lock.json | jq -r 'all(.cluster_definition.validators[]; (.fee_recipient_address | ascii_downcase) == (\"'${FEE_RECIPIENT}'\" | ascii_downcase) and (.withdrawal_address | ascii_downcase) == (\"'$(__lido_withdrawal_credentials_address)'\" | ascii_downcase))'" | tail -n 1)
        if [[ "${__cluster_lock_is_valid}" =~ "true" ]]; then
          echo "Your cluster lock is valid."
        else
          whiptail --title "Lido Obol cluster definition" --msgbox "Your cluster lock file './.eth/cluster-lock.json' is not valid.\n\nCheck that every validator has \`fee_recipient_address\` and \`withdrawal_address\` equal to Lido contracts and try again.\n\nLido fee recipient: '${FEE_RECIPIENT}'\nLido withdrawal credentials: '$(__lido_withdrawal_credentials_address)'" 14 90
          echo "Your cluster lock is NOT valid."
          exit 1
        fi
      elif (whiptail --title "Lido Obol cluster creation" --yesno "Backup a previously created cluster to create a new one?" 10 80); then
        ${__as_owner} cp -vr ./.eth ./.eth_backup_"$EPOCHSECONDS"
        ${__as_owner} rm -rf ./.eth
        __query_lido_obol_enr
        __query_lido_obol_cluster_definition
        __query_lido_obol_cluster_dkg
      else
        whiptail --title "Lido Obol cluster creation" --msgbox "The \`.eth\` folder must be empty or non-existent to continue" 10 80
        echo "The \`.eth\` folder must be empty to create a new cluster"
        exit 1
      fi
    else
      if [ -f "./.eth/charon-enr-private-key" ] && [ -f "./.eth/charon-enr-public-key" ]; then
        if (whiptail --title "Lido Obol operator ENR creation" --yesno "You already have ENR. Use it?" 8 50); then
          echo "Use existing ENR"
        else
          ${__as_owner} cp -vr ./.eth ./.eth_backup_"$EPOCHSECONDS"
          ${__as_owner} rm -rf ./.eth
          __query_lido_obol_enr
        fi
      else
        __query_lido_obol_enr
      fi

      if [ -f "./.eth/cluster-definition.json" ]; then
        if (whiptail --title "Lido Obol cluster creation in process" --yesno "You already have cluster definition. Use it?" 10 60); then
# shellcheck disable=SC2086
          __cluster_definition_is_valid=$(__docompose -f ./lido-obol.yml run --rm -v "$(pwd)"/.eth/cluster-definition.json:/cluster-definition.json:ro curl-jq sh -c \
            "cat /cluster-definition.json | jq -r 'all(.validators[]; (.fee_recipient_address | ascii_downcase) == (\"'${FEE_RECIPIENT}'\" | ascii_downcase) and (.withdrawal_address | ascii_downcase) == (\"'$(__lido_withdrawal_credentials_address)'\" | ascii_downcase))'" | tail -n 1)
          if [ "${__cluster_definition_is_valid}" = "true" ]; then
            echo "Your cluster definition is valid."
          else
            whiptail --title "Lido Obol cluster creation" --msgbox "Your cluster definition is not valid.\n\nCheck that every validator has \`fee_recipient_address\` and \`withdrawal_address\` equal to Lido contracts and try again.\n\nLido fee recipient: '${FEE_RECIPIENT}'\nLido withdrawal credentials: '$(__lido_withdrawal_credentials_address)'" 14 90
            echo "Your cluster definition is NOT valid."
            exit 1
          fi
        else
          __query_lido_obol_cluster_definition
        fi
      else
        __query_lido_obol_cluster_definition
      fi
      __query_lido_obol_cluster_dkg
    fi

# We are using the variable
# shellcheck disable=SC2034
    VE_OPERATOR_ID=$(whiptail --title "Lido Operator ID" --inputbox "Put your Operator ID from Lido Operators dashboard \
(right-click to paste)" 10 60 3>&1 1>&2 2>&3)
    __obol_prom_remote_token=$(whiptail --title "Obol prometheus" --inputbox "Put Obol Prometheus remote write token \
(right-click to paste)" 10 60 3>&1 1>&2 2>&3)
    cat ./prometheus/obol-prom.yml > ./prometheus/custom-prom.yml
    sed -i'.original' "s|      credentials: OBOL_PROM_REMOTE_WRITE_TOKEN|      credentials: ${__obol_prom_remote_token}|" ./prometheus/custom-prom.yml
    rm -f ./prometheus/custom-prom.yml.original
  fi

  if [ "${CONSENSUS_CLIENT}" = "caplin" ]; then
    COMPOSE_FILE="${EXECUTION_CLIENT}"
  else
    COMPOSE_FILE="${CONSENSUS_CLIENT}"
    if [ -n "${EXECUTION_CLIENT+x}" ]; then
      COMPOSE_FILE="${COMPOSE_FILE}:${EXECUTION_CLIENT}"
    fi
  fi
  if [[ "${__deployment}" = "ssv" || "${__deployment}" = "lido_ssv" ]]; then
    COMPOSE_FILE="${COMPOSE_FILE}:ssv.yml"
    if [[ -n "${__ssv_operator_id}" && ! "${__ssv_operator_id}" = "-1" ]]; then
      COMPOSE_FILE="${COMPOSE_FILE}:ssv-dkg.yml"
    fi
  fi
  if [ -n "${GRAFANA_CLIENT+x}" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:${GRAFANA_CLIENT}"
  fi
  if [ "${MEV_BOOST}" = "true" ] && [ ! "${__deployment}" = "rocket" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:mev-boost.yml"
  fi
  if [ "${__deployment}" = "lido_obol" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:lido-obol.yml"
  fi
  if { [ "${__deployment}" = "node" ] || [ "${__deployment}" = "rocket" ]; } \
  && [ "${NETWORK}" = "hoodi" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:deposit-cli.yml"
  fi
  if [ "${__deployment}" = "lido_csm" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:deposit-cli.yml"
  fi
# Not multi-arch, this would break on ARM64

#    COMPOSE_FILE="${COMPOSE_FILE}:ethdo.yml"
  if [ "${__deployment}" = "rocket" ]; then
    COMPOSE_FILE="${COMPOSE_FILE}:ext-network.yml"
    # Remove the sed line post-Pectra
    sed -i'.original' -e "s~name: traefik_default~name: rocketpool_net~" ext-network.yml
    DOCKER_EXT_NETWORK="rocketpool_net"
  fi

  echo "Your COMPOSE_FILE is:" "${COMPOSE_FILE}"

  __var=FEE_RECIPIENT
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=GRAFFITI
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=DEFAULT_GRAFFITI
  __update_value_in_env "${__var}" "${!__var:-"true"}" "${__env_file}"
  __var=CL_NODE
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=CHECKPOINT_SYNC_URL
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=COMPOSE_FILE
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=EL_NODE
  __update_value_in_env "${__var}" "${!__var:-"http://execution:8551"}" "${__env_file}"
  __var=JWT_SECRET
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=NETWORK
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  if [[ ${NETWORK} =~ ^https?:// ]]; then  # The aliases need to not use ${NETWORK}
    __var=W3S_ALIAS
    __update_value_in_env "${__var}" "custom-web3signer" "${__env_file}"
    __var=PG_ALIAS
    __update_value_in_env "${__var}" "custom-postgres" "${__env_file}"
    __var=CL_ALIAS
    __update_value_in_env "${__var}" "custom-consensus" "${__env_file}"
    __var=EL_ALIAS
    __update_value_in_env "${__var}" "custom-execution" "${__env_file}"
    __var=MEV_ALIAS
    __update_value_in_env "${__var}" "custom-mev" "${__env_file}"
  fi
  __var=MEV_BOOST
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=MEV_RELAYS
  __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
  __var=EL_MINIMAL_NODE
  __update_value_in_env "${__var}" "${!__var-false}" "${__env_file}"
  __var=DOCKER_EXT_NETWORK
  __update_value_in_env "${__var}" "${!__var:-"rocketpool_net"}" "${__env_file}"
  if [ "${__deployment}" = "lido_obol" ]; then
    __var=LIDO_DV_EXIT_EXIT_EPOCH
    __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
    __var=VE_OPERATOR_ID
    __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
    __var=VE_LOCATOR_ADDRESS
    __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
    __var=VE_ORACLE_ADDRESSES_ALLOWLIST
    __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
    __var=VE_STAKING_MODULE_ID
    __update_value_in_env "${__var}" "${!__var-}" "${__env_file}"
# We are using the variable
# shellcheck disable=SC2034
    ENABLE_DIST_ATTESTATION_AGGR="true"
    __var=ENABLE_DIST_ATTESTATION_AGGR
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  fi
  if [[ "${NETWORK}" = "gnosis" ]] && [[ "${CONSENSUS_CLIENT}" =~ "nimbus" ]] ; then
# We are using the variable
# shellcheck disable=SC2034
    NIM_DOCKERFILE=Dockerfile.sourcegnosis
    __var=NIM_DOCKERFILE
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  fi
  if uname -m | grep -q riscv64; then
# We are using the variable
# shellcheck disable=SC2034
    NIM_DOCKERFILE=Dockerfile.source
    __var=NIM_DOCKERFILE
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
# We are using the variable
# shellcheck disable=SC2034
    GETH_DOCKERFILE=Dockerfile.source
    __var=GETH_DOCKERFILE
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  fi
  __var="SIREN_PASSWORD"
  __get_value_from_env "${__var}" "${__env_file}" "SIREN_PASSWORD"
  if [ -z "${SIREN_PASSWORD}" ]; then
    SIREN_PASSWORD=$(head -c 8 /dev/urandom | od -A n -t u8 | tr -d '[:space:]' | sha256sum | head -c 32)
    __update_value_in_env "${__var}" "${!__var}" "${__env_file}"
  fi

  __enable_v6

  __pull_and_build
  __nag_os_version

  echo
  echo "Your configuration file is: $(dirname "$(realpath "${BASH_SOURCE[0]}")")/${__env_file}"
  echo "You can change advanced config items with \"nano .env\" when in the $(dirname "$(realpath "${BASH_SOURCE[0]}")") directory."
  echo
}


version() {
  grep "^This is" README.md
  echo
  __var="COMPOSE_FILE"
  __get_value_from_env "${__var}" "${__env_file}" "__value"
  # Client versions
  case "${__value}" in
    *lido-obol.yml* )
      __docompose exec charon charon version
      echo
      ;;&
    *ssv.yml* )
      __docompose exec ssv-node /go/bin/ssvnode --version
      echo
      ;;&
    *lighthouse.yml* | *lighthouse-cl-only* )
      __docompose exec consensus lighthouse --version
      echo
      ;;&
    *lighthouse-vc-only* )
      __docompose exec validator lighthouse --version
      echo
      ;;&
    *lodestar.yml* | *lodestar-cl-only* )
      __docompose exec consensus node /usr/app/node_modules/.bin/lodestar --version
      echo
      ;;&
    *lodestar-vc-only* )
      __docompose exec validator node /usr/app/node_modules/.bin/lodestar --version
      echo
      ;;&
    *prysm.yml* )
      __docompose exec consensus beacon-chain --version
      echo
      __docompose exec validator validator --version
      echo
      ;;&
    *prysm-cl-only* )
      __docompose exec consensus beacon-chain --version
      echo
      ;;&
    *prysm-vc-only* )
      __docompose exec validator validator --version
      echo
      ;;&
    *nimbus.yml* | *nimbus-allin1.yml* |  *nimbus-cl-only* )
      __docompose exec consensus nimbus_beacon_node --version
      echo
      ;;&
    *nimbus-vc-only* )
      __docompose exec validator nimbus_validator_client --version
      echo
      ;;&
    *teku.yml* | *teku-allin1.yml* | *teku-cl-only* )
      __docompose exec consensus /opt/teku/bin/teku --version
      echo
      ;;&
    *teku-vc-only* )
      __docompose exec validator /opt/teku/bin/teku --version
      echo
      ;;&
    *grandine.yml* | *grandine-allin1.yml* | *grandine-cl-only* )
      __docompose exec consensus grandine --version
      echo
      ;;&
    *grandine-vc-only* )
      __docompose exec validator grandine --version
      echo
      ;;&
    *vero-vc-only* )
      __docompose exec validator python main.py --version
      echo
      ;;&
    *geth.yml* )
      __docompose exec execution geth version
      echo
      ;;&
    *reth.yml* )
      __docompose exec execution reth --version
      echo
      ;;&
    *besu.yml* )
      __docompose exec execution /opt/besu/bin/besu --version
      echo
      ;;&
    *nethermind.yml* )
      echo "Nethermind version"
      __docompose exec execution /nethermind/nethermind --version
      echo
      ;;&
    *erigon.yml* )
      __docompose exec execution erigon --version
      echo
      ;;&
    *nimbus-el.yml* )
      __docompose exec execution nimbus_execution_client --version
      echo
      ;;&
    *web3signer.yml* )
      __docompose exec web3signer /opt/web3signer/bin/web3signer --version
      echo
      __docompose exec postgres pg_config --version
      echo
      ;;&
    *mev-boost.yml* )
      __docompose exec mev-boost /app/mev-boost -version
      echo
      ;;&
    *grafana.yml* )
      __docompose exec prometheus /bin/prometheus --version
      echo
      echo -n "Grafana "
      __docompose exec grafana /run.sh -v
      echo
      ;;&
    *traefik-*.yml* )
      echo "Traefik"
      __docompose exec traefik traefik version
      echo
      ;;&
    *contributoor.yml* )
      echo -n "Contributoor "
      __docompose exec contributoor sentry --release
      echo
      ;;&
  esac
}


__update_help() {
  echo "usage: $__me update [--refresh-targets] [--non-interactive]"
  echo
  echo "Updates Eth Docker itself, as required the contents of \".env\", and the clients."
  echo
  echo "A combination of \"git pull\" for Eth Docker, some bash scripting to bring new variables from \"default.env\","
  echo "and \"docker compose pull\" as well as \"docker compose build\" for the clients."
  echo
  echo "If warranted, will also offer resync when clients require it, or upgrade of PostgreSQL version."
  echo
  echo "\"--refresh-targets\" sets Docker tags, source targets, and repos of clients back to the defaults in \"default.env\"."
  echo "\"--non-interactive\" does not ask questions and assumes Yes for database resyncs and migrations."
  echo
}


__full_help() {
  echo "usage: $__me [-h|--help] <command>"
  echo
  echo "commands:"
  echo "  install"
  echo "    attempts to install Docker and Docker Compose for you"
  echo "  config"
  echo "    configures ${__project_name} with your choice of Ethereum clients"
  echo "  keys ACTION [--non-interactive]"
  echo "    list, count, delete, import keys; their fee recipients; and gas fees"
  echo "    Run without ACTION to get help text"
  echo "  update [--refresh-targets] [--non-interactive]"
  echo "    updates all client versions and ${__project_name} itself"
  echo "    --refresh-targets will reset your custom build targets in ${__env_file} to defaults"
  echo "  up|start [service-name]"
  echo "    starts the Ethereum node, or restarts containers that had their image or"
  echo "    configuration changed. Can also start a specific service by name"
  echo "  down|stop [service-name]"
  echo "    stops the Ethereum node, or a specific service by name"
  echo "  restart [service-name]"
  echo "    restarts the Ethereum node, or a specific service by name, a combination of down and up"
  echo "  version"
  echo "    prints the version(s) of currently running client(s)"
  echo "  logs"
  echo "    shows logs"
  echo "  cmd <compose-command>"
  echo "    executes an arbitrary Docker Compose command. Use \"cmd help\" to list them"
  echo "  terminate"
  echo "    stops the Ethereum node and destroys all data stores"
  echo "  prune-nethermind [--non-interactive]"
  echo "    restarts the Nethermind execution client and prunes its DB."
  echo "  prune-besu [--non-interactive]"
  echo "    stops the Besu execution client and prunes trie-logs."
  echo "  prune-reth [--non-interactive]"
  echo "    stops the Reth execution client and prunes its DB."
  echo "  prune-lighthouse [--non-interactive]"
  echo "    stops the Lighthouse consensus client and prunes state."
  echo "  resync-execution"
  echo "    removes the execution layer database and forces a resync."
  echo "  resync-consensus"
  echo "    removes the consensus layer database and forces a resync."
  echo "  space"
  echo "    show Docker volume space usage"
  echo "  attach-geth"
  echo "    launches an interactive geth attach repl"
  echo "  help"
  echo "    print this help screen"
  echo
  echo "  Instead of \"--non-interactive\" you may also use the \"ETHD_FRONTEND=noninteractive\" environment variable"
  echo
  echo "The logs command can be appended by flags and specify the container(s). Example: "
  echo
  echo "  $__me logs -f --tail 50 execution"
  echo "    shows logs only for execution service"
  echo
  echo "✍️ Give feedback and report issues on GitHub:"
  echo "  * https://github.com/eth-educators/eth-docker"
  echo "🤗 Get support on Discord:"
  echo "  * http://discord.gg/ethstaker"
}


help() {
  case $* in
    *update*) __update_help;;
    *) __full_help;;
  esac
}

# Main body from here
__env_file=.env
__during_config=0
__during_update=0
__during_postgres=0
__during_migrate=0
__migrated=0
__command=""
__me=$(basename "${BASH_SOURCE[0]}")
if [ ! -f ~/.profile ] || ! grep -q "alias ethd" ~/.profile; then
  __me="./$__me"
fi

trap '__handle_error $? $LINENO' ERR
trap '__handle_error $? $LINENO' EXIT

if [[ "$#" -eq 0 || "$*" = "--help" || "$*" = "-h" || "$*" = "update --help" || "$*" = "update -h" ]]; then
  help "$@"
  exit 0
fi

cd "$(dirname "$(realpath "${BASH_SOURCE[0]}")")"
# Use this to make sure root doesn't end up owning files
# shellcheck disable=SC2012
OWNER=$(ls -ld . | awk '{print $3}')
OWNER_GROUP=$(id -gn "${OWNER}")

if [ "${OWNER}" = "root" ]; then
  echo "Please install ${__project_name} as a non-root user."
  exit 0
fi

__command="$1"
shift
__params=$*

__handle_root
__determine_distro
__prep_conffiles

__check_for_snap

# Don't check for Docker before it's installed
if [ "$__command" = "install" ]; then
  $__command "$@"
  exit "$?"
fi

__handle_docker
__check_compose_version

if [[ "${__old_compose}" -eq 1 && "${__compose_major}" -eq 1 ]]; then
  echo
  echo "You are using docker-compose ${__compose_version}, which is unsupported by Docker, Inc."
  echo "${__project_name} only supports Compose V2."
  echo
  echo "You can install it with \"sudo apt update && sudo apt install docker-compose-v2\"."
  echo "You can remove the old docker-compose:"
  echo "\"sudo apt-mark manual docker.io && sudo apt --autoremove remove docker-compose\"."
  exit 0
fi

if [ "${__old_docker}" -eq 1 ]; then
  echo
  echo "Docker version ${__docker_version} detected. This version is no longer supported."
  echo "Please update to a current version. Supported versions can be seen at https://endoflife.date/docker-engine."
  echo
  echo "This should be as simple as \"sudo apt update && sudo apt dist-upgrade\" on Debian/Ubuntu"
  echo "or updating Docker Desktop on macOS and Windows."
  exit 0
fi

if ! type -P whiptail >/dev/null 2>&1; then
  echo "Please install the package whiptail or newt before running ${__project_name}."
  exit 0
fi

if ! __dodocker images >/dev/null 2>&1; then
  echo "Please ensure you can call $__docker_exe before running ${__project_name}."
  exit 0
fi

if ! __docompose --help >/dev/null 2>&1; then
  echo "Please ensure you can call $__compose_exe before running ${__project_name}."
  exit 0
fi

case "$__command" in
  help|config|keys|update|up|start|down|stop|restart|version|logs|cmd|terminate|prune-nethermind\
      |prune-besu|prune-reth|prune-lighthouse|resync-execution|resync-consensus|attach-geth|keyimport|space)
    $__command "$@";;
  *)
    echo "Unrecognized command $__command"
    help
    ;;
esac

__check_disk_space

if [ "${__compose_upgraded}" -eq 1 ]; then
  echo
  echo "You updated Docker Compose to V2."
  echo "The \"docker-compose\" command is gone and replaced with \"docker compose\"."
  echo
  echo "Optionally, you can switch to docker-ce."
  echo "Please see https://ethdocker.com/Usage/Prerequisites#switching-from-dockerio-to-docker-ce for instructions."
fi

if [[ "${__old_compose}" -eq 1 && "${__compose_major}" -eq 2 ]]; then
  echo "You are using Docker Compose ${__compose_version}, which has been shown to cause issues with new features"
  echo "${__project_name} may require Compose v2.18.1 or later in future"
  echo
  echo "It is recommended that you update Compose."
  if [[ ( "$__distro" =~ "debian" || "$__distro" = "ubuntu" ) ]]; then
    echo "Please do so by running: \"sudo apt update && sudo apt dist-upgrade\""
  fi
fi
